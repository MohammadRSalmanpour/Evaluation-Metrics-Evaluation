{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca75e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(digits = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0abf0",
   "metadata": {},
   "source": [
    "# 3*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c383ac",
   "metadata": {},
   "source": [
    "# Pixel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c7cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'yardstick' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'Metrics' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'Metrics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:yardstick':\n",
      "\n",
      "    accuracy, mae, mape, mase, precision, recall, rmse, smape\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    package Pixel_Accuracy\n",
      "1    Base R      0.7777778\n",
      "2    Manual      0.7777778\n",
      "3 MLmetrics      0.7777778\n",
      "4 yardstick      0.7777778\n",
      "5   Metrics      0.7777778\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(dplyr) \n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "pixel_accuracy_base_r <- sum(y_true_1 == y_pred_1) / length(y_true_1)\n",
    "\n",
    "confusion_manual <- table(y_pred_1, y_true_1)\n",
    "pixel_accuracy_manual <- sum(diag(confusion_manual)) / sum(confusion_manual)\n",
    "\n",
    "pixel_accuracy_mlmetrics <- MLmetrics::Accuracy(as.numeric(y_pred_1), as.numeric(y_true_1))\n",
    "\n",
    "data <- tibble(\n",
    "  truth = y_true_1,\n",
    "  estimate = y_pred_1\n",
    ")\n",
    "metrics_results <- data %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "pixel_accuracy_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"accuracy\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "pixel_accuracy_metrics <- accuracy(as.numeric(y_true_1), as.numeric(y_pred_1))\n",
    "\n",
    "accuracy_results <- data.frame(\n",
    "  package = c(\"Base R\", \"Manual\", \"MLmetrics\", \"yardstick\", \n",
    "             \"Metrics\"),\n",
    "  Pixel_Accuracy = c(pixel_accuracy_base_r, pixel_accuracy_manual, pixel_accuracy_mlmetrics, \n",
    "                     pixel_accuracy_yardstick, \n",
    "                     pixel_accuracy_metrics)\n",
    ")\n",
    "\n",
    "print(accuracy_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2adbfe7",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50a7f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y_true_1\n",
      "y_pred_1 0 1\n",
      "       0 3 1\n",
      "       1 1 4\n",
      "    package Precision\n",
      "1    Base R      0.80\n",
      "2 MLmetrics      0.75\n",
      "3 yardstick      0.75\n",
      "4   Metrics      0.80\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(dplyr) \n",
    "set.seed(42)\n",
    "\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "\n",
    "confusion_matrix_base_r <- table(y_pred_1, y_true_1)\n",
    "print(confusion_matrix_base_r)  \n",
    "precision_base_r <- diag(confusion_matrix_base_r)[2] / sum(confusion_matrix_base_r[, 2])\n",
    "\n",
    "data <- tibble(\n",
    "  truth = y_true_1,\n",
    "  estimate = y_pred_1\n",
    ")\n",
    "\n",
    "precision_yardstick <- precision_vec(truth = data$truth, estimate = data$estimate, estimator = \"binary\")\n",
    "\n",
    "precision_mlmetrics <- MLmetrics::Precision(as.numeric(y_pred_1), as.numeric(y_true_1), positive = 1)\n",
    "\n",
    "precision_metrics <- Metrics::precision(as.numeric(as.character(y_true_1)), as.numeric(as.character(y_pred_1)))\n",
    "\n",
    "precision_results <- data.frame(\n",
    "  package = c(\"Base R\", \"MLmetrics\", \"yardstick\", \"Metrics\"),\n",
    "  Precision = c(precision_base_r, precision_mlmetrics, precision_yardstick, precision_metrics)\n",
    ")\n",
    "\n",
    "print(precision_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a34e8c",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10443105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'e1071' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'DescTools' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'DescTools'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:MLmetrics':\n",
      "\n",
      "    AUC, Gini, MAE, MAPE, MSE, RMSE\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y_true_1\n",
      "y_pred_1 0 1\n",
      "       0 3 1\n",
      "       1 1 4\n",
      "[1] \"Recall Base R: 0.8\"\n",
      "[1] \"Recall MLmetrics: 0.75\"\n",
      "[1] \"Recall Metrics: 0.8\"\n",
      "    package Recall\n",
      "1    Base R   0.80\n",
      "2 MLmetrics   0.75\n",
      "3   Metrics   0.80\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(e1071)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(DescTools)\n",
    "library(dplyr) \n",
    "\n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "confusion_matrix_base_r <- table(y_pred_1, y_true_1)\n",
    "print(confusion_matrix_base_r)  \n",
    "recall_base_r <- diag(confusion_matrix_base_r)[2] / sum(confusion_matrix_base_r[2,])\n",
    "\n",
    "recall_mlmetrics <- MLmetrics::Recall(as.numeric(y_pred_1), as.numeric(y_true_1), positive = 1)\n",
    "\n",
    "recall_metrics <- Metrics::recall(as.numeric(as.character(y_true_1)), as.numeric(as.character(y_pred_1)))\n",
    "\n",
    "print(paste(\"Recall Base R:\", recall_base_r))\n",
    "print(paste(\"Recall MLmetrics:\", recall_mlmetrics))\n",
    "print(paste(\"Recall Metrics:\", recall_metrics))\n",
    "\n",
    "recall_results <- data.frame(\n",
    "  package = c(\"Base R\", \"MLmetrics\", \"Metrics\"),\n",
    "  Recall = c(recall_base_r, recall_mlmetrics, recall_metrics)\n",
    ")\n",
    "\n",
    "print(recall_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f959f",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f0ef891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"F1 Score Manual: 0.8\"\n",
      "[1] \"F1 Score MLmetrics: 0.75\"\n",
      "[1] \"F1 Score yardstick: \"\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(DescTools)\n",
    "library(dplyr) \n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "confusion_manual <- table(y_pred_1, y_true_1)\n",
    "precision_manual <- diag(confusion_manual) / colSums(confusion_manual)\n",
    "recall_manual <- diag(confusion_manual) / rowSums(confusion_manual)\n",
    "f1_score_manual <- 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
    "\n",
    "f1_score_mlmetrics <- F1_Score(as.numeric(y_pred_1), as.numeric(y_true_1), positive = 1)\n",
    "\n",
    "data <- tibble(\n",
    "  truth = y_true_1,\n",
    "  estimate = y_pred_1\n",
    ")\n",
    "metrics_results <- data %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "\n",
    "f1_score_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"f_meas\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "print(paste(\"F1 Score Manual:\", f1_score_manual[\"1\"]))\n",
    "print(paste(\"F1 Score MLmetrics:\", f1_score_mlmetrics))\n",
    "print(paste(\"F1 Score yardstick:\", f1_score_yardstick))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2048d",
   "metadata": {},
   "source": [
    "# Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a85d553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dice Coefficient Base R: 0.8\"\n",
      "[1] \"Dice Coefficient Manual: 0.8\"\n",
      "  method    Dice_Coefficient\n",
      "1 Base R 0.80000000000000004\n",
      "2 Manual 0.80000000000000004\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(ModelMetrics)\n",
    "library(DescTools)\n",
    "library(dplyr)\n",
    "\n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "dice_coefficient <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class)\n",
    "  if (union == 0) return(NA)  \n",
    "  2 * intersection / union\n",
    "}\n",
    "\n",
    "intersection_base_r <- sum(y_true_1 == y_pred_1 & y_true_1 == \"1\")\n",
    "union_base_r <- sum(y_true_1 == \"1\") + sum(y_pred_1 == \"1\")\n",
    "dice_base_r <- 2 * intersection_base_r / union_base_r\n",
    "\n",
    "confusion_manual <- table(y_pred_1, y_true_1)\n",
    "intersection_manual <- confusion_manual[\"1\", \"1\"]\n",
    "union_manual <- sum(confusion_manual[\"1\", ]) + sum(confusion_manual[, \"1\"])\n",
    "dice_manual <- 2 * intersection_manual / union_manual\n",
    "\n",
    "print(paste(\"Dice Coefficient Base R:\", dice_base_r))\n",
    "print(paste(\"Dice Coefficient Manual:\", dice_manual))\n",
    "\n",
    "dice_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  Dice_Coefficient = c(dice_base_r, dice_manual)\n",
    ")\n",
    "\n",
    "print(dice_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212091b",
   "metadata": {},
   "source": [
    "# IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de391a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ModelMetrics' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'ModelMetrics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:Metrics':\n",
      "\n",
      "    auc, ce, logLoss, mae, mse, msle, precision, recall, rmse, rmsle\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:yardstick':\n",
      "\n",
      "    mae, mcc, npv, ppv, precision, recall, rmse, sensitivity,\n",
      "    specificity\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    kappa\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"IoU/Jaccard Index Base R: 0.666666666666667\"\n",
      "[1] \"IoU/Jaccard Index Manual: 0.666666666666667\"\n",
      "  method IoU_Jaccard_Index\n",
      "1 Base R         0.6666667\n",
      "2 Manual         0.6666667\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(ModelMetrics)\n",
    "library(DescTools)\n",
    "library(dplyr)\n",
    "\n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "iou_jaccard <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class) - intersection\n",
    "  if (union == 0) return(NA)  \n",
    "  intersection / union\n",
    "}\n",
    "\n",
    "intersection_base_r <- sum(y_true_1 == y_pred_1 & y_true_1 == \"1\")\n",
    "union_base_r <- sum(y_true_1 == \"1\") + sum(y_pred_1 == \"1\") - intersection_base_r\n",
    "iou_base_r <- intersection_base_r / union_base_r\n",
    "\n",
    "confusion_manual <- table(y_pred_1, y_true_1)\n",
    "intersection_manual <- confusion_manual[\"1\", \"1\"]\n",
    "union_manual <- sum(confusion_manual[\"1\", ]) + sum(confusion_manual[, \"1\"]) - intersection_manual\n",
    "iou_manual <- intersection_manual / union_manual\n",
    "\n",
    "print(paste(\"IoU/Jaccard Index Base R:\", iou_base_r))\n",
    "print(paste(\"IoU/Jaccard Index Manual:\", iou_manual))\n",
    "\n",
    "iou_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  IoU_Jaccard_Index = c(iou_base_r, iou_manual)\n",
    ")\n",
    "\n",
    "print(iou_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac79a0",
   "metadata": {},
   "source": [
    "# Mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0614ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean IoU Base R: 0.633333333333333\"\n",
      "[1] \"Mean IoU Manual: 0.633333333333333\"\n",
      "  method  Mean_IoU\n",
      "1 Base R 0.6333333\n",
      "2 Manual 0.6333333\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(ModelMetrics)\n",
    "library(DescTools)\n",
    "library(dplyr)\n",
    "\n",
    "set.seed(42)\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "iou_jaccard <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class) - intersection\n",
    "  if (union == 0) return(NA)  \n",
    "  intersection / union\n",
    "}\n",
    "\n",
    "mean_iou <- function(y_true, y_pred) {\n",
    "  classes <- unique(c(y_true, y_pred))\n",
    "  iou_values <- sapply(classes, function(cls) {\n",
    "    iou_jaccard(y_true, y_pred, cls)\n",
    "  })\n",
    "  mean(iou_values, na.rm = TRUE)  \n",
    "}\n",
    "\n",
    "mean_iou_base_r <- mean_iou(y_true_1, y_pred_1)\n",
    "\n",
    "confusion_manual <- table(y_pred_1, y_true_1)\n",
    "y_true_numeric <- as.numeric(as.character(y_true_1))\n",
    "y_pred_numeric <- as.numeric(as.character(y_pred_1))\n",
    "mean_iou_manual <- mean_iou(as.factor(y_true_numeric), as.factor(y_pred_numeric))\n",
    "\n",
    "print(paste(\"Mean IoU Base R:\", mean_iou_base_r))\n",
    "print(paste(\"Mean IoU Manual:\", mean_iou_manual))\n",
    "\n",
    "iou_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  Mean_IoU = c(mean_iou_base_r, mean_iou_manual)\n",
    ")\n",
    "\n",
    "print(iou_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ff1c6",
   "metadata": {},
   "source": [
    "# Boundary F1 Score (BF Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc7c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Boundary F1 Score (BF Score): 0.8\"\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "\n",
    "y_true <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "y_true_numeric <- as.numeric(y_true) - 1\n",
    "y_pred_numeric <- as.numeric(y_pred) - 1\n",
    "\n",
    "true_positives <- sum(y_true_numeric == 1 & y_pred_numeric == 1)\n",
    "false_positives <- sum(y_true_numeric == 0 & y_pred_numeric == 1)\n",
    "false_negatives <- sum(y_true_numeric == 1 & y_pred_numeric == 0)\n",
    "\n",
    "precision <- true_positives / (true_positives + false_positives)\n",
    "recall <- true_positives / (true_positives + false_negatives)\n",
    "\n",
    "bf_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(paste(\"Boundary F1 Score (BF Score):\", round(bf_score, 4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d29843",
   "metadata": {},
   "source": [
    "# Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021fccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "                package Hausdorff_Distance\n",
      "1 Custom Implementation                  1\n"
     ]
    }
   ],
   "source": [
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "y_true_vec <- as.numeric(y_true_1)\n",
    "y_pred_vec <- as.numeric(y_pred_1)\n",
    "\n",
    "y_true_mat <- matrix(y_true_vec, nrow = 1)\n",
    "y_pred_mat <- matrix(y_pred_vec, nrow = 1)\n",
    "\n",
    "detect_boundary_points <- function(mat) {\n",
    "  boundary_points <- which(mat == 1, arr.ind = TRUE)\n",
    "  return(boundary_points)\n",
    "}\n",
    "\n",
    "euclidean_distance <- function(p1, p2) {\n",
    "  sqrt(sum((p1 - p2)^2))\n",
    "}\n",
    "\n",
    "hausdorff_distance <- function(true_points, pred_points) {\n",
    "  \n",
    "  max_dist_true_to_pred <- max(sapply(1:nrow(true_points), function(i) {\n",
    "    min(sapply(1:nrow(pred_points), function(j) {\n",
    "      euclidean_distance(true_points[i, ], pred_points[j, ])\n",
    "    }))\n",
    "  }))\n",
    "  \n",
    "  max_dist_pred_to_true <- max(sapply(1:nrow(pred_points), function(i) {\n",
    "    min(sapply(1:nrow(true_points), function(j) {\n",
    "      euclidean_distance(pred_points[i, ], true_points[j, ])\n",
    "    }))\n",
    "  }))\n",
    "  \n",
    "  \n",
    "  hausdorff_dist <- max(max_dist_true_to_pred, max_dist_pred_to_true)\n",
    "  \n",
    "  return(hausdorff_dist)\n",
    "}\n",
    "\n",
    "true_points <- detect_boundary_points(y_true_mat)\n",
    "pred_points <- detect_boundary_points(y_pred_mat)\n",
    "\n",
    "if (nrow(true_points) > 0 && nrow(pred_points) > 0) {\n",
    "  \n",
    "  hausdorff_dist_value <- hausdorff_distance(true_points, pred_points)\n",
    "} else {\n",
    "  hausdorff_dist_value <- NA\n",
    "  warning(\"One of the input matrices has no boundary points.\")\n",
    "}\n",
    "\n",
    "print(hausdorff_dist_value)\n",
    "\n",
    "hausdorff_results <- data.frame(\n",
    "  package = \"Custom Implementation\",\n",
    "  Hausdorff_Distance = hausdorff_dist_value\n",
    ")\n",
    "\n",
    "print(hausdorff_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469d2f7",
   "metadata": {},
   "source": [
    "# Geometric Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68260bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.8\n",
      "[1] 0.8\n",
      "[1] 0.8\n",
      "[1] 0.8\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "\n",
    "y_true <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "precision <- sum(y_true == 1 & y_pred == 1) / sum(y_pred == 1)\n",
    "recall <- sum(y_true == 1 & y_pred == 1) / sum(y_true == 1)\n",
    "\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "geometric_mean_precision_recall <- sqrt(precision * recall)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)\n",
    "print(geometric_mean_precision_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140cb39",
   "metadata": {},
   "source": [
    "# kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c7857fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method Kappa\n",
      "1    Base R  0.55\n",
      "2 yardstick  0.55\n"
     ]
    }
   ],
   "source": [
    "library(yardstick)\n",
    "\n",
    "y_true_1 <- as.factor(c(0, 1, 1, 0, 0, 1, 1, 1, 0))\n",
    "y_pred_1 <- as.factor(c(0, 1, 1, 0, 1, 1, 1, 0, 0))\n",
    "\n",
    "data <- data.frame(\n",
    "  truth = y_true_1,\n",
    "  estimate = y_pred_1\n",
    ")\n",
    "\n",
    "conf_matrix <- table(data$truth, data$estimate)\n",
    "p0 <- sum(diag(conf_matrix)) / sum(conf_matrix)  \n",
    "p1 <- sum(rowSums(conf_matrix) * colSums(conf_matrix)) / (sum(conf_matrix)^2)  \n",
    "kappa_base_r <- (p0 - p1) / (1 - p1)\n",
    "\n",
    "metrics_results <- data %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "\n",
    "kappa_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"kap\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "results <- data.frame(\n",
    "  Method = c(\"Base R\", \"yardstick\"),\n",
    "  Kappa = c(kappa_base_r, kappa_yardstick)\n",
    ")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56256ac2",
   "metadata": {},
   "source": [
    "# 128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87bf89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'readxl' was built under R version 4.3.3\"\n"
     ]
    }
   ],
   "source": [
    "library(readxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a962c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " y\\_true & y\\_pred\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 0 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| y_true &lt;dbl&gt; | y_pred &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 0 | 0 |\n",
       "| 1 | 1 |\n",
       "| 0 | 1 |\n",
       "| 0 | 1 |\n",
       "| 0 | 0 |\n",
       "| 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  y_true y_pred\n",
       "1 0      0     \n",
       "2 1      1     \n",
       "3 0      1     \n",
       "4 0      1     \n",
       "5 0      0     \n",
       "6 1      1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "head(data)\n",
    "y_true  <- data$y_true\n",
    "y_pred <- data$y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef7130",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aae1296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " y\\_true & y\\_pred\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 0 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| y_true &lt;dbl&gt; | y_pred &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 0 | 0 |\n",
       "| 1 | 1 |\n",
       "| 0 | 1 |\n",
       "| 0 | 1 |\n",
       "| 0 | 0 |\n",
       "| 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  y_true y_pred\n",
       "1 0      0     \n",
       "2 1      1     \n",
       "3 0      1     \n",
       "4 0      1     \n",
       "5 0      0     \n",
       "6 1      1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    package Pixel_Accuracy\n",
      "1    Base R  0.49560546875\n",
      "2    Manual  0.49560546875\n",
      "3 MLmetrics  0.49560546875\n",
      "4 yardstick  0.49560546875\n",
      "5   Metrics  0.49560546875\n"
     ]
    }
   ],
   "source": [
    "library(readxl)  \n",
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(dplyr)\n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "head(data)\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "pixel_accuracy_base_r <- sum(y_true == y_pred) / length(y_true)\n",
    "\n",
    "confusion_manual <- table(y_pred, y_true)\n",
    "pixel_accuracy_manual <- sum(diag(confusion_manual)) / sum(confusion_manual)\n",
    "\n",
    "pixel_accuracy_mlmetrics <- MLmetrics::Accuracy(as.numeric(y_pred), as.numeric(y_true))\n",
    "\n",
    "data_tibble <- tibble(\n",
    "  truth = y_true,\n",
    "  estimate = y_pred\n",
    ")\n",
    "\n",
    "metrics_results <- data_tibble %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "\n",
    "pixel_accuracy_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"accuracy\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "pixel_accuracy_metrics <- accuracy(as.numeric(y_true), as.numeric(y_pred))\n",
    "\n",
    "accuracy_results <- data.frame(\n",
    "  package = c(\"Base R\", \"Manual\", \"MLmetrics\", \"yardstick\", \"Metrics\"),\n",
    "  Pixel_Accuracy = c(pixel_accuracy_base_r, pixel_accuracy_manual, pixel_accuracy_mlmetrics, pixel_accuracy_yardstick, pixel_accuracy_metrics)\n",
    ")\n",
    "\n",
    "print(accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85254eb6",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6122a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Precision: 0.492205438066465\"\n",
      "    package Precision\n",
      "1 MLmetrics 0.4906049\n",
      "2 yardstick 0.4990751\n",
      "3   Metrics 0.4922054\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(dplyr) \n",
    "library(readxl) \n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "true_positives <- sum(y_true == 1 & y_pred == 1)\n",
    "false_positives <- sum(y_true == 0 & y_pred == 1)\n",
    "precision <- true_positives / (true_positives + false_positives)\n",
    "print(paste(\"Precision:\", precision))\n",
    "\n",
    "data_tibble <- tibble(\n",
    "  truth = y_true,\n",
    "  estimate = y_pred\n",
    ")\n",
    "\n",
    "precision_yardstick <- precision_vec(truth = data_tibble$truth, estimate = data_tibble$estimate, estimator = \"binary\")\n",
    "\n",
    "precision_mlmetrics <- MLmetrics::Precision(as.numeric(y_pred), as.numeric(y_true), positive = 1)\n",
    "\n",
    "precision_metrics <- Metrics::precision(as.numeric(as.character(y_true)), as.numeric(as.character(y_pred)))\n",
    "\n",
    "precision_results <- data.frame(\n",
    "  package = c(\"MLmetrics\", \"yardstick\", \"Metrics\"),\n",
    "  Precision = c(precision_mlmetrics, precision_yardstick, precision_metrics)\n",
    ")\n",
    "\n",
    "print(precision_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703729b",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2434a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Recall Base R: 0.500676090964966\"\n",
      "[1] \"Recall Metrics: 0.500676090964966\"\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(dplyr) \n",
    "library(readxl) \n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "confusion_matrix <- table(data$y_true, data$y_pred)\n",
    "TP <- confusion_matrix[2, 2]  \n",
    "FN <- confusion_matrix[2, 1]  \n",
    "\n",
    "recall <- TP / (TP + FN)\n",
    "\n",
    "recall_metrics <- Metrics::recall(as.numeric(as.character(y_true)), as.numeric(as.character(y_pred)))\n",
    "\n",
    "print(paste(\"Recall Base R:\", recall))\n",
    "print(paste(\"Recall Metrics:\", recall_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fb72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Recall MLmetrics: 0.500676090964966\"\n"
     ]
    }
   ],
   "source": [
    "y_true_numeric <- as.numeric(as.character(y_true))\n",
    "y_pred_numeric <- as.numeric(as.character(y_pred))\n",
    "\n",
    "recall_mlmetrics <- MLmetrics::Recall(y_true_numeric, y_pred_numeric, positive = 1)\n",
    "\n",
    "print(paste(\"Recall MLmetrics:\", recall_mlmetrics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6e04b",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2ed08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'readxl' was built under R version 4.3.3\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"F1 Score Manual: 0.496404631322364\"\n",
      "[1] \"F1 Score MLmetrics: 0.494803765741533\"\n",
      "[1] \"F1 Score yardstick: \"\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(DescTools)\n",
    "library(dplyr) \n",
    "library(readxl) \n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "confusion_manual <- table(y_pred, y_true)\n",
    "precision_manual <- diag(confusion_manual) / colSums(confusion_manual)\n",
    "recall_manual <- diag(confusion_manual) / rowSums(confusion_manual)\n",
    "f1_score_manual <- 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
    "f1_score_manual_value <- f1_score_manual[\"1\"]  \n",
    "\n",
    "f1_score_mlmetrics <- F1_Score(as.numeric(y_pred), as.numeric(y_true), positive = 1)\n",
    "\n",
    "data_tibble <- tibble(\n",
    "  truth = y_true,\n",
    "  estimate = y_pred\n",
    ")\n",
    "\n",
    "metrics_results <- data_tibble %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "\n",
    "f1_score_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"f_meas\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "print(paste(\"F1 Score Manual:\", f1_score_manual_value))\n",
    "print(paste(\"F1 Score MLmetrics:\", f1_score_mlmetrics))\n",
    "print(paste(\"F1 Score yardstick:\", f1_score_yardstick))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d49ccd",
   "metadata": {},
   "source": [
    "# IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb4266a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"IoU/Jaccard Index Base R: 0.330145091999676\"\n",
      "[1] \"IoU/Jaccard Index Manual: 0.330145091999676\"\n",
      "  method   IoU_Jaccard_Index\n",
      "1 Base R 0.33014509199967579\n",
      "2 Manual 0.33014509199967579\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(ModelMetrics)\n",
    "library(DescTools)\n",
    "library(dplyr)\n",
    "library(readxl) \n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "iou_jaccard <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class) - intersection\n",
    "  if (union == 0) return(NA)  \n",
    "  intersection / union\n",
    "}\n",
    "\n",
    "intersection_base_r <- sum(y_true == y_pred & y_true == \"1\")\n",
    "union_base_r <- sum(y_true == \"1\") + sum(y_pred == \"1\") - intersection_base_r\n",
    "iou_base_r <- intersection_base_r / union_base_r\n",
    "\n",
    "confusion_manual <- table(y_pred, y_true)\n",
    "intersection_manual <- confusion_manual[\"1\", \"1\"]\n",
    "union_manual <- sum(confusion_manual[\"1\", ]) + sum(confusion_manual[, \"1\"]) - intersection_manual\n",
    "iou_manual <- intersection_manual / union_manual\n",
    "\n",
    "print(paste(\"IoU/Jaccard Index Base R:\", iou_base_r))\n",
    "print(paste(\"IoU/Jaccard Index Manual:\", iou_manual))\n",
    "\n",
    "iou_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  IoU_Jaccard_Index = c(iou_base_r, iou_manual)\n",
    ")\n",
    "\n",
    "print(iou_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad800c88",
   "metadata": {},
   "source": [
    "# kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c450e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method        Kappa\n",
      "1    Base R -0.008717951\n",
      "2 yardstick -0.008717951\n"
     ]
    }
   ],
   "source": [
    "library(yardstick)\n",
    "library(readxl) \n",
    "library(dplyr)\n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "data_df <- data.frame(\n",
    "  truth = y_true,\n",
    "  estimate = y_pred\n",
    ")\n",
    "\n",
    "conf_matrix <- table(data_df$truth, data_df$estimate)\n",
    "p0 <- sum(diag(conf_matrix)) / sum(conf_matrix)  \n",
    "p1 <- sum(rowSums(conf_matrix) * colSums(conf_matrix)) / (sum(conf_matrix)^2)  \n",
    "kappa_base_r <- (p0 - p1) / (1 - p1)\n",
    "\n",
    "metrics_results <- data_df %>%\n",
    "  metrics(truth = truth, estimate = estimate)\n",
    "\n",
    "kappa_yardstick <- metrics_results %>%\n",
    "  filter(.metric == \"kap\") %>%\n",
    "  pull(.estimate)\n",
    "\n",
    "results <- data.frame(\n",
    "  Method = c(\"Base R\", \"yardstick\"),\n",
    "  Kappa = c(kappa_base_r, kappa_yardstick)\n",
    ")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045445f",
   "metadata": {},
   "source": [
    "# Boundary F1 Score (BF Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54561568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Boundary F1 Score (BF Score): 0.4964\"\n"
     ]
    }
   ],
   "source": [
    "library(readxl)\n",
    "library(dplyr)\n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "y_true_numeric <- as.numeric(data$y_true)\n",
    "y_pred_numeric <- as.numeric(data$y_pred)\n",
    "\n",
    "true_positives <- sum(y_true_numeric == 1 & y_pred_numeric == 1)\n",
    "false_positives <- sum(y_true_numeric == 0 & y_pred_numeric == 1)\n",
    "false_negatives <- sum(y_true_numeric == 1 & y_pred_numeric == 0)\n",
    "\n",
    "precision <- true_positives / (true_positives + false_positives)\n",
    "recall <- true_positives / (true_positives + false_negatives)\n",
    "\n",
    "bf_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(paste(\"Boundary F1 Score (BF Score):\", round(bf_score, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b531337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.4964046\n"
     ]
    }
   ],
   "source": [
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "colnames(data) <- c(\"y_true\", \"y_pred\")\n",
    "\n",
    "data$y_true <- as.factor(data$y_true)\n",
    "data$y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "conf_matrix <- table(data$y_true, data$y_pred)\n",
    "\n",
    "TP <- conf_matrix[\"1\", \"1\"]\n",
    "FP <- conf_matrix[\"0\", \"1\"]\n",
    "FN <- conf_matrix[\"1\", \"0\"]\n",
    "TN <- conf_matrix[\"0\", \"0\"]\n",
    "\n",
    "precision <- TP / (TP + FP)\n",
    "recall <- TP / (TP + FN)\n",
    "\n",
    "bf_score <- (1 + 1^2) * (precision * recall) / (1^2 * precision + recall)\n",
    "\n",
    "print(bf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d43b9",
   "metadata": {},
   "source": [
    "# Mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17127e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean IoU Base R: 0.32943774785184\"\n",
      "[1] \"Mean IoU Manual: 0.32943774785184\"\n",
      "  method            Mean_IoU\n",
      "1 Base R 0.32943774785184016\n",
      "2 Manual 0.32943774785184016\n"
     ]
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(ModelMetrics)\n",
    "library(DescTools)\n",
    "library(dplyr)\n",
    "library(readxl) \n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "iou_jaccard <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class) - intersection\n",
    "  if (union == 0) return(NA)  \n",
    "  intersection / union\n",
    "}\n",
    "\n",
    "mean_iou <- function(y_true, y_pred) {\n",
    "  classes <- unique(c(y_true, y_pred))\n",
    "  iou_values <- sapply(classes, function(cls) {\n",
    "    iou_jaccard(y_true, y_pred, cls)\n",
    "  })\n",
    "  mean(iou_values, na.rm = TRUE)  \n",
    "}\n",
    "\n",
    "mean_iou_base_r <- mean_iou(y_true, y_pred)\n",
    "\n",
    "confusion_manual <- table(y_pred, y_true)\n",
    "y_true_numeric <- as.numeric(as.character(y_true))\n",
    "y_pred_numeric <- as.numeric(as.character(y_pred))\n",
    "mean_iou_manual <- mean_iou(as.factor(y_true_numeric), as.factor(y_pred_numeric))\n",
    "\n",
    "print(paste(\"Mean IoU Base R:\", mean_iou_base_r))\n",
    "print(paste(\"Mean IoU Manual:\", mean_iou_manual))\n",
    "\n",
    "iou_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  Mean_IoU = c(mean_iou_base_r, mean_iou_manual)\n",
    ")\n",
    "\n",
    "print(iou_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e3e11",
   "metadata": {},
   "source": [
    "# Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "y_true_vec <- as.numeric(y_true)\n",
    "y_pred_vec <- as.numeric(y_pred)\n",
    "\n",
    "y_true_mat <- matrix(y_true_vec, nrow = 1)\n",
    "y_pred_mat <- matrix(y_pred_vec, nrow = 1)\n",
    "\n",
    "detect_boundary_points <- function(mat) {\n",
    "  boundary_points <- which(mat == 1, arr.ind = TRUE)\n",
    "  return(boundary_points)\n",
    "}\n",
    "\n",
    "euclidean_distance <- function(p1, p2) {\n",
    "  sqrt(sum((p1 - p2)^2))\n",
    "}\n",
    "\n",
    "hausdorff_distance <- function(true_points, pred_points) {\n",
    "  \n",
    "  max_dist_true_to_pred <- max(sapply(1:nrow(true_points), function(i) {\n",
    "    min(sapply(1:nrow(pred_points), function(j) {\n",
    "      euclidean_distance(true_points[i, ], pred_points[j, ])\n",
    "    }))\n",
    "  }))\n",
    "  \n",
    "  max_dist_pred_to_true <- max(sapply(1:nrow(pred_points), function(i) {\n",
    "    min(sapply(1:nrow(true_points), function(j) {\n",
    "      euclidean_distance(pred_points[i, ], true_points[j, ])\n",
    "    }))\n",
    "  }))\n",
    "  \n",
    "  \n",
    "  hausdorff_dist <- max(max_dist_true_to_pred, max_dist_pred_to_true)\n",
    "  \n",
    "  return(hausdorff_dist)\n",
    "}\n",
    "\n",
    "true_points <- detect_boundary_points(y_true_mat)\n",
    "pred_points <- detect_boundary_points(y_pred_mat)\n",
    "\n",
    "\n",
    "if (nrow(true_points) > 0 && nrow(pred_points) > 0) {\n",
    "  \n",
    "  hausdorff_dist_value <- hausdorff_distance(true_points, pred_points)\n",
    "} else {\n",
    "  hausdorff_dist_value <- NA\n",
    "  warning(\"One of the input matrices has no boundary points.\")\n",
    "}\n",
    "\n",
    "print(paste(\"Hausdorff Distance:\", hausdorff_dist_value))\n",
    "\n",
    "hausdorff_results <- data.frame(\n",
    "  package = \"Custom Implementation\",\n",
    "  Hausdorff_Distance = hausdorff_dist_value\n",
    ")\n",
    "\n",
    "print(hausdorff_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde56eaf",
   "metadata": {},
   "source": [
    "# Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d7ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'readxl' was built under R version 4.3.3\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dice Coefficient Base R: 0.496404631322364\"\n",
      "[1] \"Dice Coefficient Manual: 0.496404631322364\"\n",
      "  method Dice_Coefficient\n",
      "1 Base R        0.4964046\n",
      "2 Manual        0.4964046\n"
     ]
    }
   ],
   "source": [
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "y_true <- as.factor(data$y_true)\n",
    "y_pred <- as.factor(data$y_pred)\n",
    "\n",
    "dice_coefficient <- function(y_true, y_pred, positive_class) {\n",
    "  intersection <- sum(y_true == y_pred & y_true == positive_class)\n",
    "  union <- sum(y_true == positive_class) + sum(y_pred == positive_class)\n",
    "  if (union == 0) return(NA)  \n",
    "  2 * intersection / union\n",
    "}\n",
    "\n",
    "intersection_base_r <- sum(y_true == y_pred & y_true == \"1\")\n",
    "union_base_r <- sum(y_true == \"1\") + sum(y_pred == \"1\")\n",
    "dice_base_r <- 2 * intersection_base_r / union_base_r\n",
    "\n",
    "confusion_manual <- table(y_pred, y_true)\n",
    "intersection_manual <- confusion_manual[\"1\", \"1\"]\n",
    "union_manual <- sum(confusion_manual[\"1\", ]) + sum(confusion_manual[, \"1\"])\n",
    "dice_manual <- 2 * intersection_manual / union_manual\n",
    "\n",
    "print(paste(\"Dice Coefficient Base R:\", dice_base_r))\n",
    "print(paste(\"Dice Coefficient Manual:\", dice_manual))\n",
    "\n",
    "dice_results <- data.frame(\n",
    "  method = c(\"Base R\", \"Manual\"),\n",
    "  Dice_Coefficient = c(dice_base_r, dice_manual)\n",
    ")\n",
    "\n",
    "print(dice_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274ea66",
   "metadata": {},
   "source": [
    "# Geometric Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "library(dplyr)\n",
    "\n",
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/binary_segmentation.xlsx\")\n",
    "\n",
    "precision <- sum(data$y_true & data$y_pred) / sum(data$y_pred)\n",
    "recall <- sum(data$y_true & data$y_pred) / sum(data$y_true)\n",
    "\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "geometric_mean_precision_recall <- sqrt(precision * recall)\n",
    "\n",
    "print(geometric_mean_precision_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b722b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
