{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b8ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'readxl' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 4.3.3\"\n",
      "Loading required package: lattice\n",
      "\n",
      "Warning message:\n",
      "\"package 'lattice' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'yardstick' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'yardstick'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    precision, recall, sensitivity, specificity\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'Metrics' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'Metrics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:yardstick':\n",
      "\n",
      "    accuracy, mae, mape, mase, precision, recall, rmse, smape\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    precision, recall\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'e1071' was built under R version 4.3.3\"\n",
      "Warning message:\n",
      "\"package 'Hmisc' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'Hmisc'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:e1071':\n",
      "\n",
      "    impute\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    format.pval, units\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'psych' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'psych'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:MLmetrics':\n",
      "\n",
      "    AUC\n",
      "\n",
      "\n",
      "The following object is masked from 'package:Hmisc':\n",
      "\n",
      "    describe\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:ggplot2':\n",
      "\n",
      "    %+%, alpha\n",
      "\n",
      "\n",
      "Loading required package: lpSolve\n",
      "\n",
      "Warning message:\n",
      "\"package 'lpSolve' was built under R version 4.3.2\"\n",
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:Hmisc':\n",
      "\n",
      "    src, summarize\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readxl)\n",
    "library(ggplot2)\n",
    "library(caret)\n",
    "library(yardstick)\n",
    "library(tibble)\n",
    "library(Metrics)\n",
    "library(e1071)\n",
    "library(ROCR)\n",
    "library(Hmisc)\n",
    "library(MLmetrics)\n",
    "library(mccr)\n",
    "library(psych)\n",
    "library(irr)\n",
    "library(ROCR)\n",
    "library(PRROC)\n",
    "library(dplyr)\n",
    "library(readxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737670d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th><th scope=col>y_pred_proba</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3</td><td>3</td><td>0.17</td></tr>\n",
       "\t<tr><td>4</td><td>4</td><td>0.44</td></tr>\n",
       "\t<tr><td>5</td><td>5</td><td>0.30</td></tr>\n",
       "\t<tr><td>4</td><td>4</td><td>0.36</td></tr>\n",
       "\t<tr><td>5</td><td>5</td><td>0.17</td></tr>\n",
       "\t<tr><td>4</td><td>4</td><td>0.47</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " y\\_true & y\\_pred & y\\_pred\\_proba\\\\\n",
       " <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3 & 3 & 0.17\\\\\n",
       "\t 4 & 4 & 0.44\\\\\n",
       "\t 5 & 5 & 0.30\\\\\n",
       "\t 4 & 4 & 0.36\\\\\n",
       "\t 5 & 5 & 0.17\\\\\n",
       "\t 4 & 4 & 0.47\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| y_true &lt;dbl&gt; | y_pred &lt;dbl&gt; | y_pred_proba &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 3 | 3 | 0.17 |\n",
       "| 4 | 4 | 0.44 |\n",
       "| 5 | 5 | 0.30 |\n",
       "| 4 | 4 | 0.36 |\n",
       "| 5 | 5 | 0.17 |\n",
       "| 4 | 4 | 0.47 |\n",
       "\n"
      ],
      "text/plain": [
       "  y_true y_pred y_pred_proba\n",
       "1 3      3      0.17        \n",
       "2 4      4      0.44        \n",
       "3 5      5      0.30        \n",
       "4 4      4      0.36        \n",
       "5 5      5      0.17        \n",
       "6 4      4      0.47        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data <- read_excel(\"C:/Users/SADEGHI/Desktop/US_MRI_Data.xlsx\")\n",
    "head(data)\n",
    "y_true  <- data$y_true\n",
    "y_pred <- data$y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d8faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes <- length(unique(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8508866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Accuracy: 0.788135593220339\n",
      "Precision per class:\n",
      "  Class 3: 0.937500000000000\n",
      "  Class 4: 0.600000000000000\n",
      "  Class 5: 0.900000000000000\n",
      "Macro Precision: 0.812500000000000\n",
      "Micro Precision: 0.788135593220339\n",
      "Weighted Precision: 0.829449152542373\n",
      "Recall per class:\n",
      "  Class 3: 0.900000000000000\n",
      "  Class 4: 0.882352941176471\n",
      "  Class 5: 0.529411764705882\n",
      "Macro Recall: 0.770588235294118\n",
      "Micro Recall: 0.788135593220339\n",
      "Weighted Recall: 0.788135593220339\n",
      "F1 Score per class:\n",
      "  Class 3: 0.918367346938776\n",
      "  Class 4: 0.714285714285714\n",
      "  Class 5: 0.666666666666667\n",
      "Macro F1 Score: 0.766439909297052\n",
      "Micro F1 Score: 0.788135593220339\n",
      "Weighted F1 Score: 0.787040239824743\n",
      "F_beta Score (beta=0.5): 0.788135593220339\n",
      "MCC per class:\n",
      "  Class 3: 0.860961818027281\n",
      "  Class 4: 0.590471938285626\n",
      "  Class 5: 0.610323448812662\n",
      "Macro MCC: 0.687252401708523\n",
      "Balanced Accuracy per class:\n",
      "  Class 3: 0.927941176470588\n",
      "  Class 4: 0.822128851540616\n",
      "  Class 5: 0.752801120448179\n",
      "Macro Balanced Accuracy: 0.834290382819795\n",
      "Weighted Balanced Accuracy: 0.770588235294118\n",
      "Jaccard Index per class:\n",
      "  Class 3: 0.849056603773585\n",
      "  Class 4: 0.555555555555556\n",
      "  Class 5: 0.500000000000000\n",
      "Macro Jaccard: 0.634870719776380\n",
      "Micro Jaccard: 0.650349650349650\n",
      "Weighted Jaccard: 0.663912873538713\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy <- sum(y_true == y_pred) / length(y_true)\n",
    "conf_matrix <- table(y_true, y_pred)\n",
    "class_support <- table(y_true)\n",
    "tp <- sum(diag(conf_matrix))  # True Positives\n",
    "fp <- sum(rowSums(conf_matrix)) - tp  # False Positives\n",
    "fn <- sum(colSums(conf_matrix)) - tp  # False Negatives\n",
    "precision_per_class <- diag(conf_matrix) / colSums(conf_matrix)\n",
    "macro_precision <- mean(precision_per_class, na.rm = TRUE)\n",
    "micro_precision <- tp / (tp + fp)\n",
    "support <- rowSums(conf_matrix)\n",
    "weighted_precision <- sum(precision_per_class * support) / sum(support)\n",
    "recall_per_class <- diag(conf_matrix) / rowSums(conf_matrix)\n",
    "macro_recall <- mean(recall_per_class, na.rm = TRUE)\n",
    "micro_recall <- tp / (tp + fn)\n",
    "weighted_recall <- sum(recall_per_class * support) / sum(support)\n",
    "f1_per_class <- 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class)\n",
    "macro_f1 <- mean(f1_per_class, na.rm = TRUE)\n",
    "micro_f1 <- tp / (tp + 0.5 * (fp + fn))\n",
    "weighted_f1 <- sum(f1_per_class * support) / sum(support)\n",
    "f_beta_score <- function(tp, fp, fn, beta = 0.5) {\n",
    "  \n",
    "  precision <- tp / (tp + fp)\n",
    "  recall <- tp / (tp + fn)\n",
    "  \n",
    "  \n",
    "  f_beta <- (1 + beta^2) * (precision * recall) / ((beta^2 * precision) + recall)\n",
    "  \n",
    "  return(f_beta)\n",
    "}\n",
    "f_beta <- f_beta_score(tp, fp, fn, beta = 0.5)\n",
    "class_labels <- levels(factor(y_true))\n",
    "calculate_mcc <- function(class_label, conf_matrix) {\n",
    "  tp <- conf_matrix[class_label, class_label]  # True Positives for the class\n",
    "  fn <- sum(conf_matrix[class_label, ]) - tp  # False Negatives for the class\n",
    "  fp <- sum(conf_matrix[, class_label]) - tp  # False Positives for the class\n",
    "  tn <- sum(conf_matrix) - tp - fp - fn  # True Negatives for the class\n",
    "  \n",
    "  # MCC formula\n",
    "  numerator <- (tp * tn) - (fp * fn)\n",
    "  denominator <- sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "  \n",
    "  if (is.na(denominator) || denominator == 0) {\n",
    "    return(0)\n",
    "  } else {\n",
    "    return(numerator / denominator)\n",
    "  }\n",
    "}\n",
    "mcc_per_class <- sapply(class_labels, function(label) calculate_mcc(label, conf_matrix))\n",
    "macro_mcc <- mean(mcc_per_class)\n",
    "calculate_balanced_accuracy <- function(class_label, conf_matrix) {\n",
    "  tp <- conf_matrix[class_label, class_label]\n",
    "  fn <- sum(conf_matrix[class_label, ]) - tp\n",
    "  fp <- sum(conf_matrix[, class_label]) - tp\n",
    "  tn <- sum(conf_matrix) - (tp + fn + fp)\n",
    "\n",
    "  TPR <- tp / (tp + fn)  # True Positive Rate (Sensitivity)\n",
    "  TNR <- tn / (tn + fp)  # True Negative Rate (Specificity)\n",
    "  \n",
    "  balanced_accuracy <- (TPR + TNR) / 2\n",
    "  \n",
    "  return(balanced_accuracy)\n",
    "}\n",
    "balanced_accuracy_per_class <- sapply(class_labels, function(label) calculate_balanced_accuracy(label, conf_matrix))\n",
    "macro_balanced_accuracy <- mean(balanced_accuracy_per_class)\n",
    "TP <- diag(conf_matrix)\n",
    "FN <- rowSums(conf_matrix) - TP\n",
    "recall_per_class <- TP / (TP + FN)\n",
    "n <- length(unique(y_true))\n",
    "weighted_balanced_accuracy <- sum(recall_per_class) / n\n",
    "TP <- diag(conf_matrix)\n",
    "FP <- colSums(conf_matrix) - TP\n",
    "FN <- rowSums(conf_matrix) - TP\n",
    "\n",
    "jaccard_per_class <- TP / (TP + FP + FN)\n",
    "macro_jaccard <- mean(jaccard_per_class, na.rm = TRUE)\n",
    "micro_tp <- sum(TP)\n",
    "micro_fp <- sum(FP)\n",
    "micro_fn <- sum(FN)\n",
    "micro_jaccard <- micro_tp / (micro_tp + micro_fp + micro_fn)\n",
    "weighted_jaccard <- sum(jaccard_per_class * class_support) / sum(class_support)\n",
    "results <- list(\n",
    "  accuracy = sprintf(\"%.15f\", accuracy),\n",
    "  precision_per_class = setNames(as.list(sprintf(\"%.15f\", precision_per_class)), class_labels),\n",
    "  macro_precision = sprintf(\"%.15f\", macro_precision),\n",
    "  micro_precision = sprintf(\"%.15f\", micro_precision),\n",
    "  weighted_precision = sprintf(\"%.15f\", weighted_precision),\n",
    "  recall_per_class = setNames(as.list(sprintf(\"%.15f\", recall_per_class)), class_labels),\n",
    "  macro_recall = sprintf(\"%.15f\", macro_recall),\n",
    "  micro_recall = sprintf(\"%.15f\", micro_recall),\n",
    "  weighted_recall = sprintf(\"%.15f\", weighted_recall),\n",
    "  f1_per_class = setNames(as.list(sprintf(\"%.15f\", f1_per_class)), class_labels),\n",
    "  macro_f1 = sprintf(\"%.15f\", macro_f1),\n",
    "  micro_f1 = sprintf(\"%.15f\", micro_f1),\n",
    "  weighted_f1 = sprintf(\"%.15f\", weighted_f1),\n",
    "  f_beta_score = sprintf(\"%.15f\", f_beta),\n",
    "  mcc_per_class = setNames(as.list(sprintf(\"%.15f\", mcc_per_class)), class_labels),\n",
    "  macro_mcc = sprintf(\"%.15f\", macro_mcc),\n",
    "  balanced_accuracy_per_class = setNames(as.list(sprintf(\"%.15f\", balanced_accuracy_per_class)), class_labels),\n",
    "  macro_balanced_accuracy = sprintf(\"%.15f\", macro_balanced_accuracy),\n",
    "  weighted_balanced_accuracy = sprintf(\"%.15f\", weighted_balanced_accuracy),\n",
    "  jaccard_per_class = setNames(as.list(sprintf(\"%.15f\", jaccard_per_class)), class_labels),\n",
    "  macro_jaccard = sprintf(\"%.15f\", macro_jaccard),\n",
    "  micro_jaccard = sprintf(\"%.15f\", micro_jaccard),\n",
    "  weighted_jaccard = sprintf(\"%.15f\", weighted_jaccard)\n",
    ")\n",
    "cat(\"Results:\\n\")\n",
    "cat(sprintf(\"Accuracy: %s\\n\", results$accuracy))\n",
    "cat(\"Precision per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$precision_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro Precision: %s\\n\", results$macro_precision))\n",
    "cat(sprintf(\"Micro Precision: %s\\n\", results$micro_precision))\n",
    "cat(sprintf(\"Weighted Precision: %s\\n\", results$weighted_precision))\n",
    "\n",
    "cat(\"Recall per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$recall_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro Recall: %s\\n\", results$macro_recall))\n",
    "cat(sprintf(\"Micro Recall: %s\\n\", results$micro_recall))\n",
    "cat(sprintf(\"Weighted Recall: %s\\n\", results$weighted_recall))\n",
    "\n",
    "cat(\"F1 Score per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$f1_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro F1 Score: %s\\n\", results$macro_f1))\n",
    "cat(sprintf(\"Micro F1 Score: %s\\n\", results$micro_f1))\n",
    "cat(sprintf(\"Weighted F1 Score: %s\\n\", results$weighted_f1))\n",
    "\n",
    "cat(sprintf(\"F_beta Score (beta=0.5): %s\\n\", results$f_beta_score))\n",
    "\n",
    "cat(\"MCC per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$mcc_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro MCC: %s\\n\", results$macro_mcc))\n",
    "\n",
    "cat(\"Balanced Accuracy per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$balanced_accuracy_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro Balanced Accuracy: %s\\n\", results$macro_balanced_accuracy))\n",
    "cat(sprintf(\"Weighted Balanced Accuracy: %s\\n\", results$weighted_balanced_accuracy))\n",
    "\n",
    "cat(\"Jaccard Index per class:\\n\")\n",
    "for (class in class_labels) {\n",
    "  cat(sprintf(\"  Class %s: %s\\n\", class, results$jaccard_per_class[[class]]))\n",
    "}\n",
    "cat(sprintf(\"Macro Jaccard: %s\\n\", results$macro_jaccard))\n",
    "cat(sprintf(\"Micro Jaccard: %s\\n\", results$micro_jaccard))\n",
    "cat(sprintf(\"Weighted Jaccard: %s\\n\", results$weighted_jaccard))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b8cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (caret): 0.788135593220339\n",
      "\n",
      "Recall per class:\n",
      "Class 3: 0.900000000000000\n",
      "Class 4: 0.882352941176471\n",
      "Class 5: 0.529411764705882\n",
      "Macro Recall (caret): 0.770588235294118\n",
      "Weighted Recall (caret): 0.788135593220339\n",
      "Micro Recall (caret): 0.788135593220339\n",
      "\n",
      "Precision per class:\n",
      "Class 3: 0.937500000000000\n",
      "Class 4: 0.600000000000000\n",
      "Class 5: 0.900000000000000\n",
      "Macro Precision (caret): 0.812500000000000\n",
      "Micro Precision (caret): 0.788135593220339\n",
      "Weighted Precision (caret): 0.829449152542373\n",
      "\n",
      "F1 Score per class:\n",
      "Class 3: 0.918367346938776\n",
      "Class 4: 0.714285714285714\n",
      "Class 5: 0.666666666666667\n",
      "Macro F1 Score (caret): 0.766439909297052\n",
      "Weighted F1 Score (caret): 0.787040239824743\n",
      "Micro F1 Score (caret): 0.788135593220339\n",
      "\n",
      "Kappa (caret): 0.677384076990376\n",
      "\n",
      "MCC (caret): 0.682203389830508\n",
      "\n",
      "Balanced Accuracy (caret): 0.834290382819795\n",
      "\n",
      "Jaccard Index per class:\n",
      "Class 3: 0.849056603773585\n",
      "Class 4: 0.555555555555556\n",
      "Class 5: 0.500000000000000\n",
      "Macro Jaccard Index (caret): 0.634870719776380\n",
      "Micro Jaccard Index (caret): 0.650349650349650\n",
      "Weighted Jaccard Index (caret): 0.663912873538713\n"
     ]
    }
   ],
   "source": [
    "confMatrix <- confusionMatrix(factor(y_pred), factor(y_true))\n",
    "cm_table <- confMatrix$table\n",
    "class_labels <- levels(factor(y_true)) \n",
    "TP <- diag(cm_table)\n",
    "FP <- colSums(cm_table) - TP\n",
    "FN <- rowSums(cm_table) - TP\n",
    "class_support <- table(factor(y_true))  \n",
    "accuracy <- confMatrix$overall['Accuracy']\n",
    "cat(sprintf(\"Accuracy (caret): %.15f\\n\", accuracy))\n",
    "recall_per_class <- confMatrix$byClass[, \"Sensitivity\"]\n",
    "macro_recall <- mean(recall_per_class, na.rm = TRUE)\n",
    "weighted_recall <- sum(recall_per_class * (class_support / sum(class_support)))\n",
    "micro_recall <- sum(TP) / (sum(TP) + sum(FN))\n",
    "\n",
    "cat(\"\\nRecall per class:\\n\")\n",
    "for (i in 1:length(class_labels)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", class_labels[i], recall_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro Recall (caret): %.15f\\n\", macro_recall))\n",
    "cat(sprintf(\"Weighted Recall (caret): %.15f\\n\", weighted_recall))\n",
    "cat(sprintf(\"Micro Recall (caret): %.15f\\n\", micro_recall))\n",
    "precision_per_class <- confMatrix$byClass[, \"Precision\"]\n",
    "macro_precision <- mean(precision_per_class, na.rm = TRUE)\n",
    "micro_precision <- sum(TP) / (sum(TP) + sum(FP))\n",
    "weighted_precision <- sum(precision_per_class * (class_support / sum(class_support)))\n",
    "\n",
    "cat(\"\\nPrecision per class:\\n\")\n",
    "for (i in 1:length(class_labels)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", class_labels[i], precision_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro Precision (caret): %.15f\\n\", macro_precision))\n",
    "cat(sprintf(\"Micro Precision (caret): %.15f\\n\", micro_precision))\n",
    "cat(sprintf(\"Weighted Precision (caret): %.15f\\n\", weighted_precision))\n",
    "f1_per_class <- 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class)\n",
    "macro_f1 <- mean(f1_per_class, na.rm = TRUE)\n",
    "weighted_f1 <- sum(f1_per_class * (class_support / sum(class_support)))\n",
    "micro_f1 <- 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "\n",
    "cat(\"\\nF1 Score per class:\\n\")\n",
    "for (i in 1:length(class_labels)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", class_labels[i], f1_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro F1 Score (caret): %.15f\\n\", macro_f1))\n",
    "cat(sprintf(\"Weighted F1 Score (caret): %.15f\\n\", weighted_f1))\n",
    "cat(sprintf(\"Micro F1 Score (caret): %.15f\\n\", micro_f1))\n",
    "kappa_base <- confMatrix$overall['Kappa']\n",
    "cat(sprintf(\"\\nKappa (caret): %.15f\\n\", kappa_base))\n",
    "tp_sum <- 0\n",
    "tn_sum <- 0\n",
    "fp_sum <- 0\n",
    "fn_sum <- 0\n",
    "\n",
    "for (i in 1:length(class_labels)) {\n",
    "  tp <- cm_table[i, i]\n",
    "  fn <- sum(cm_table[i, ]) - tp\n",
    "  fp <- sum(cm_table[, i]) - tp\n",
    "  tn <- sum(cm_table) - (tp + fn + fp)\n",
    "  \n",
    "  tp_sum <- tp_sum + tp\n",
    "  tn_sum <- tn_sum + tn\n",
    "  fp_sum <- fp_sum + fp\n",
    "  fn_sum <- fn_sum + fn\n",
    "}\n",
    "\n",
    "numerator <- (tp_sum * tn_sum) - (fp_sum * fn_sum)\n",
    "denominator <- sqrt((tp_sum + fp_sum) * (tp_sum + fn_sum) * (tn_sum + fp_sum) * (tn_sum + fn_sum))\n",
    "mcc1 <- ifelse(denominator == 0, 0, numerator / denominator)  # Handle division by zero\n",
    "cat(sprintf(\"\\nMCC (caret): %.15f\\n\", mcc1))\n",
    "balanced_acc <- mean(confMatrix$byClass[,\"Balanced Accuracy\"])\n",
    "cat(sprintf(\"\\nBalanced Accuracy (caret): %.15f\\n\", balanced_acc))\n",
    "jaccard_per_class <- TP / (TP + FP + FN)\n",
    "macro_jaccard <- mean(jaccard_per_class, na.rm = TRUE)\n",
    "micro_tp <- sum(TP)\n",
    "micro_fp <- sum(FP)\n",
    "micro_fn <- sum(FN)\n",
    "micro_jaccard <- micro_tp / (micro_tp + micro_fp + micro_fn)\n",
    "weighted_jaccard <- sum(jaccard_per_class * (class_support / sum(class_support)))\n",
    "\n",
    "cat(\"\\nJaccard Index per class:\\n\")\n",
    "for (i in 1:length(class_labels)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", class_labels[i], jaccard_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro Jaccard Index (caret): %.15f\\n\", macro_jaccard))\n",
    "cat(sprintf(\"Micro Jaccard Index (caret): %.15f\\n\", micro_jaccard))\n",
    "cat(sprintf(\"Weighted Jaccard Index (caret): %.15f\\n\", weighted_jaccard))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fa1caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (MLmetrics): 0.788135593220339\n",
      "\n",
      "Class-based Recall (MLmetrics):\n",
      "Class 3: 0.900000000000000\n",
      "Class 4: 0.882352941176471\n",
      "Class 5: 0.529411764705882\n",
      "Macro Recall (MLmetrics): 0.770588235294118\n",
      "Weighted Recall (MLmetrics): 0.788135593220339\n",
      "Micro Recall (MLmetrics): 0.788135593220339\n",
      "\n",
      "Class-based Precision (MLmetrics):\n",
      "Class 3: 0.937500000000000\n",
      "Class 4: 0.600000000000000\n",
      "Class 5: 0.900000000000000\n",
      "Macro Precision (MLmetrics): 0.812500000000000\n",
      "Weighted Precision (MLmetrics): 0.829449152542373\n",
      "Micro Precision (MLmetrics): 0.788135593220339\n",
      "\n",
      "Class-based F1 Score (MLmetrics):\n",
      "Class 3: 0.942028985507246\n",
      "Class 4: 0.842105263157895\n",
      "Class 5: 0.901098901098901\n",
      "Macro F1 Score (MLmetrics): 0.895077716588014\n",
      "Weighted F1 Score (MLmetrics): 0.901443990339774\n",
      "Micro F1 Score (MLmetrics): 0.788135593220339\n"
     ]
    }
   ],
   "source": [
    "accuracy <- Accuracy(y_pred, y_true)\n",
    "cat(sprintf(\"Accuracy (MLmetrics): %.15f\\n\", accuracy))\n",
    "conf_table <- table(y_true, y_pred)\n",
    "TP <- diag(conf_table)\n",
    "FN <- rowSums(conf_table) - TP\n",
    "class_support <- table(y_true)  \n",
    "recall_per_class <- sapply(levels(factor(y_true)), function(class) {\n",
    "  Recall(y_pred = y_pred, y_true = y_true, positive = class)\n",
    "})\n",
    "\n",
    "macro_recall <- mean(recall_per_class, na.rm = TRUE)\n",
    "micro_recall <- sum(TP) / (sum(TP) + sum(FN))\n",
    "weighted_recall <- sum(recall_per_class * (class_support / sum(class_support)))\n",
    "\n",
    "cat(\"\\nClass-based Recall (MLmetrics):\\n\")\n",
    "for (i in 1:length(recall_per_class)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", levels(factor(y_true))[i], recall_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro Recall (MLmetrics): %.15f\\n\", macro_recall))\n",
    "cat(sprintf(\"Weighted Recall (MLmetrics): %.15f\\n\", weighted_recall))\n",
    "cat(sprintf(\"Micro Recall (MLmetrics): %.15f\\n\", micro_recall))\n",
    "actual <- factor(y_true, levels = unique(c(y_true, y_pred)))\n",
    "predicted <- factor(y_pred, levels = unique(c(y_true, y_pred)))\n",
    "\n",
    "precision_per_class <- sapply(levels(actual), function(class) {\n",
    "  Precision(y_pred = predicted, y_true = actual, positive = class)\n",
    "})\n",
    "\n",
    "macro_precision <- mean(precision_per_class, na.rm = TRUE)\n",
    "micro_precision <- sum(TP) / (sum(TP) + sum(FP))  \n",
    "FP <- colSums(conf_table) - TP\n",
    "weighted_precision <- sum(precision_per_class * (class_support / sum(class_support)))\n",
    "\n",
    "cat(\"\\nClass-based Precision (MLmetrics):\\n\")\n",
    "for (i in 1:length(precision_per_class)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", levels(factor(y_true))[i], precision_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro Precision (MLmetrics): %.15f\\n\", macro_precision))\n",
    "cat(sprintf(\"Weighted Precision (MLmetrics): %.15f\\n\", weighted_precision))\n",
    "cat(sprintf(\"Micro Precision (MLmetrics): %.15f\\n\", micro_precision))\n",
    "f1_scores_per_class <- sapply(levels(factor(y_true)), function(cls) {\n",
    "  cls_numeric <- as.numeric(cls)\n",
    "  y_true_binary <- as.numeric(y_true == cls_numeric)\n",
    "  y_pred_binary <- as.numeric(y_pred == cls_numeric)\n",
    "  F1_Score(y_true_binary, y_pred_binary)\n",
    "})\n",
    "\n",
    "macro_f1 <- mean(f1_scores_per_class, na.rm = TRUE)\n",
    "weighted_f1 <- sum(f1_scores_per_class * (class_support / sum(class_support)))\n",
    "micro_f1 <- 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "\n",
    "cat(\"\\nClass-based F1 Score (MLmetrics):\\n\")\n",
    "for (i in 1:length(f1_scores_per_class)) {\n",
    "  cat(sprintf(\"Class %s: %.15f\\n\", levels(factor(y_true))[i], f1_scores_per_class[i]))\n",
    "}\n",
    "cat(sprintf(\"Macro F1 Score (MLmetrics): %.15f\\n\", macro_f1))\n",
    "cat(sprintf(\"Weighted F1 Score (MLmetrics): %.15f\\n\", weighted_f1))\n",
    "cat(sprintf(\"Micro F1 Score (MLmetrics): %.15f\\n\", micro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "299013c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Accuracy (yardstick): 0.788135593220339'"
      ],
      "text/latex": [
       "'Accuracy (yardstick): 0.788135593220339'"
      ],
      "text/markdown": [
       "'Accuracy (yardstick): 0.788135593220339'"
      ],
      "text/plain": [
       "[1] \"Accuracy (yardstick): 0.788135593220339\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Balanced Accuracy (yardstick): 0.834290382819795'"
      ],
      "text/latex": [
       "'Balanced Accuracy (yardstick): 0.834290382819795'"
      ],
      "text/markdown": [
       "'Balanced Accuracy (yardstick): 0.834290382819795'"
      ],
      "text/plain": [
       "[1] \"Balanced Accuracy (yardstick): 0.834290382819795\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Macro F-beta Score (yardstick): 0.786750463783957'"
      ],
      "text/latex": [
       "'Macro F-beta Score (yardstick): 0.786750463783957'"
      ],
      "text/markdown": [
       "'Macro F-beta Score (yardstick): 0.786750463783957'"
      ],
      "text/plain": [
       "[1] \"Macro F-beta Score (yardstick): 0.786750463783957\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Micro F-beta Score (yardstick): 0.788135593220339'"
      ],
      "text/latex": [
       "'Micro F-beta Score (yardstick): 0.788135593220339'"
      ],
      "text/markdown": [
       "'Micro F-beta Score (yardstick): 0.788135593220339'"
      ],
      "text/plain": [
       "[1] \"Micro F-beta Score (yardstick): 0.788135593220339\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Weighted F-beta Score (yardstick): 0.806140511557753'"
      ],
      "text/latex": [
       "'Weighted F-beta Score (yardstick): 0.806140511557753'"
      ],
      "text/markdown": [
       "'Weighted F-beta Score (yardstick): 0.806140511557753'"
      ],
      "text/plain": [
       "[1] \"Weighted F-beta Score (yardstick): 0.806140511557753\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 <- data.frame(actual = factor(y_true), predicted = factor(y_pred))\n",
    "results <- data1 %>%\n",
    "  metrics(truth = actual, estimate = predicted)\n",
    "accuracy_result <- results %>% filter(.metric == \"accuracy\")\n",
    "sprintf(\"Accuracy (yardstick): %.15f\", accuracy_result$.estimate)\n",
    "precision_result <- results %>% filter(.metric == \"precision\")\n",
    "sprintf(\"Precision (yardstick): %.15f\", precision_result$.estimate)\n",
    "recall_result <- results %>% filter(.metric == \"recall\")\n",
    "sprintf(\"Recall (yardstick): %.15f\", recall_result$.estimate)\n",
    "f1_result <- results %>% filter(.metric == \"f_meas\")\n",
    "sprintf(\"F1 Score (yardstick): %.15f\", f1_result$.estimate)\n",
    "kappa_result <- data1 %>%\n",
    "  kappa(truth = actual, estimate = predicted)\n",
    "sprintf(\"Kappa (yardstick): %.15f\", kappa_result$.estimate)\n",
    "bal_acc_result <- data1 %>%\n",
    "  bal_accuracy(truth = actual, estimate = predicted)\n",
    "sprintf(\"Balanced Accuracy (yardstick): %.15f\", bal_acc_result$.estimate)\n",
    "fbeta_macro_result <- data1 %>%\n",
    "  f_meas(truth = actual, estimate = predicted, beta = 0.5, estimator = \"macro\")\n",
    "sprintf(\"Macro F-beta Score (yardstick): %.15f\", fbeta_macro_result$.estimate)\n",
    "\n",
    "fbeta_micro_result <- data1 %>%\n",
    "  f_meas(truth = actual, estimate = predicted, beta = 0.5, estimator = \"micro\")\n",
    "sprintf(\"Micro F-beta Score (yardstick): %.15f\", fbeta_micro_result$.estimate)\n",
    "fbeta_weighted_result <- data1 %>%\n",
    "  f_meas(truth = actual, estimate = predicted, beta = 0.5, estimator = \"macro_weighted\")\n",
    "sprintf(\"Weighted F-beta Score (yardstick): %.15f\", fbeta_weighted_result$.estimate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c23df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Cohen\\'s Kappa (e1071): 0.677384076990376'"
      ],
      "text/latex": [
       "'Cohen\\textbackslash{}'s Kappa (e1071): 0.677384076990376'"
      ],
      "text/markdown": [
       "'Cohen\\'s Kappa (e1071): 0.677384076990376'"
      ],
      "text/plain": [
       "[1] \"Cohen's Kappa (e1071): 0.677384076990376\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### e1071 Library ###\n",
    "kappa_e1071 <- kappa(conf_matrix)\n",
    "sprintf(\"Cohen's Kappa (e1071): %.15f\", kappa_e1071$coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0268861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Cohen\\'s Kappa (psych): 0.677384076990376'"
      ],
      "text/latex": [
       "'Cohen\\textbackslash{}'s Kappa (psych): 0.677384076990376'"
      ],
      "text/markdown": [
       "'Cohen\\'s Kappa (psych): 0.677384076990376'"
      ],
      "text/plain": [
       "[1] \"Cohen's Kappa (psych): 0.677384076990376\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Psych Library ###\n",
    "kappa_psych <- cohen.kappa(conf_matrix)\n",
    "sprintf(\"Cohen's Kappa (psych): %.15f\", kappa_psych$kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a900b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Cohen\\'s Kappa (irr): 0.677384076990376'"
      ],
      "text/latex": [
       "'Cohen\\textbackslash{}'s Kappa (irr): 0.677384076990376'"
      ],
      "text/markdown": [
       "'Cohen\\'s Kappa (irr): 0.677384076990376'"
      ],
      "text/plain": [
       "[1] \"Cohen's Kappa (irr): 0.677384076990376\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### IRR Library ###\n",
    "kappa_irr <- kappa2(data1)\n",
    "sprintf(\"Cohen's Kappa (irr): %.15f\", kappa_irr$value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82d068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e577e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e446826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
