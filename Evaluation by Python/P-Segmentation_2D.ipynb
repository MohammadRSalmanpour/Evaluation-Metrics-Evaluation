{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22432,"status":"ok","timestamp":1729951506491,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"JKmAN5AXZeA7","outputId":"8f6e2a80-b692-4bb0-d6fc-31d336556472"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":42854,"status":"ok","timestamp":1729951552668,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"zKMddqSywn0V","outputId":"bc4fb28a-7f50-4fcb-b765-7ef33dcf322b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy\u003c2.0,\u003e1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging\u003e17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n","Collecting lightning-utilities\u003e=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (75.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (3.0.2)\n","Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n","Requirement already satisfied: numpy\u003c3,\u003e=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)\n","Requirement already satisfied: scipy!=1.9.2,\u003e=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n","Requirement already satisfied: pandas!=2.1.0,\u003e=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)\n","Requirement already satisfied: patsy\u003e=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n","Requirement already satisfied: packaging\u003e=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,\u003e=1.4-\u003estatsmodels) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,\u003e=1.4-\u003estatsmodels) (2024.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,\u003e=1.4-\u003estatsmodels) (2024.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy\u003e=0.5.6-\u003estatsmodels) (1.16.0)\n","Collecting datasets\n","  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow\u003e=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests\u003e=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess\u003c0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec\u003c=2024.9.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]\u003c=2024.9.0,\u003e=2023.1.0-\u003edatasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (2.4.3)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (24.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.1.0)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.16.0)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003edatasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (3.4.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets) (1.16.0)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl\u003c2.0,\u003e=1.12.0-\u003eaiohttp-\u003edatasets) (0.2.0)\n","Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n","Collecting SimpleITK\n","  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n","Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.4.0\n","Collecting medpy\n","  Downloading medpy-0.5.2.tar.gz (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy\u003e=1.10 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.13.1)\n","Requirement already satisfied: numpy\u003e=1.24 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.26.4)\n","Requirement already satisfied: SimpleITK\u003e=2.1 in /usr/local/lib/python3.10/dist-packages (from medpy) (2.4.0)\n","Building wheels for collected packages: medpy\n","  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for medpy: filename=MedPy-0.5.2-cp310-cp310-linux_x86_64.whl size=762834 sha256=d2d71649cd387aa1ca788b3d69d48bf83bdffef4afa540a3d2f46794fae3ad4d\n","  Stored in directory: /root/.cache/pip/wheels/a1/b8/63/bdf557940ec60d1b8822e73ff9fbe7727ac19f009d46b5d175\n","Successfully built medpy\n","Installing collected packages: medpy\n","Successfully installed medpy-0.5.2\n","Collecting hausdorff\n","  Downloading hausdorff-0.2.6.tar.gz (16 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: hausdorff\n","  Building wheel for hausdorff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hausdorff: filename=hausdorff-0.2.6-py3-none-any.whl size=15186 sha256=6aaea6e76d2c86ceb77b49be7397d3d023b4aecfc1f874cf761efa6c8a6df590\n","  Stored in directory: /root/.cache/pip/wheels/cd/9e/ee/d7c81175a113c77a1169316da33a6491b29920365dc001256a\n","Successfully built hausdorff\n","Installing collected packages: hausdorff\n","Successfully installed hausdorff-0.2.6\n"]}],"source":["!pip install torchmetrics\n","!pip install statsmodels\n","!pip install datasets\n","!pip install SimpleITK\n","!pip install medpy\n","!pip install hausdorff"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1729952252577,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"xlPQtjr4ERH3"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from decimal import getcontext, Decimal\n","import tensorflow as tf\n","import pandas as pd\n","import torch\n","import torchmetrics\n","import torchvision.transforms as transforms\n","from torchmetrics.functional import dice\n","from torchmetrics import Precision, Recall\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score, cohen_kappa_score\n","from skimage.morphology import binary_dilation, binary_erosion, disk\n","import numpy as np\n","from skimage.morphology import binary_dilation, disk\n","from skimage.measure import label\n","from scipy.ndimage import binary_erosion\n","from skimage.metrics import hausdorff_distance\n","import SimpleITK as sitk\n","import numpy as np\n","from scipy.ndimage import binary_erosion\n","from skimage.morphology import binary_dilation, disk\n","from medpy.metric.binary import hd95, __surface_distances\n","from medpy.metric.binary import dc, hd, jc, precision, recall\n","from imblearn.metrics import geometric_mean_score\n","from scipy.spatial.distance import directed_hausdorff\n","from hausdorff import hausdorff_distance\n","from tensorflow.keras.metrics import Precision, Recall"]},{"cell_type":"markdown","metadata":{"id":"0g-tCw--z80J"},"source":["#**Data**"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1729951599372,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"FxcIujt8NInX"},"outputs":[],"source":["np.set_printoptions(precision=25)\n","getcontext().prec = 25\n","pd.options.display.float_format = '{:.25f}'.format\n","np.set_printoptions(precision=25)\n","pd.set_option('display.float_format', '{:.25f}'.format)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":428,"status":"ok","timestamp":1729951625787,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"kl8ufQz08f0J"},"outputs":[],"source":["# Sample data 1: Generate random binary segmentation masks\n","\n","np.random.seed(42)\n","y_true = np.random.randint(0, 2, (128, 128)).astype(np.int32)\n","y_pred = np.random.randint(0, 2, (128, 128)).astype(np.int32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FGMLR978jKp"},"outputs":[],"source":["# Sample data 2: binary segmentation masks\n","\n","y_true = np.array([[0, 1, 1], [0, 0, 1], [1, 1, 0]])\n","y_pred = np.array([[0, 1, 1], [0, 1, 1], [1, 0, 0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o61V5hYK9K2M"},"outputs":[],"source":["# Sample data 3: 3D binary segmentation masks\n","\n","np.random.seed(42)\n","image_shape = (64, 64, 64)\n","y_true = np.random.randint(0, 2, size=image_shape).astype(np.float32)\n","y_pred = np.random.randint(0, 2, size=image_shape).astype(np.float32)\n","y_true_flat = y_true.reshape(-1, 1)\n","y_pred_flat = y_pred.reshape(-1, 1)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1729951630705,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"gV4h9F0GEqOO"},"outputs":[],"source":["y_true_flat = y_true.flatten()\n","y_pred_flat = y_pred.flatten()\n","results = {}"]},{"cell_type":"markdown","metadata":{"id":"FKfvT1ADFAdX"},"source":["#**TensorFlow Library:**"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4241,"status":"ok","timestamp":1729952001242,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"61QJEBRYFAqd"},"outputs":[],"source":["y_true_tf = tf.convert_to_tensor(y_true, dtype=tf.float32)\n","y_pred_tf = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n","\n","tf_accuracy = tf.keras.metrics.BinaryAccuracy()\n","tf_precision = tf.keras.metrics.Precision()\n","tf_recall = tf.keras.metrics.Recall()\n","\n","tf_meaniou = tf.keras.metrics.MeanIoU(num_classes=2)\n","tf_iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n","tf_f1 = tf.keras.metrics.F1Score(average = 'micro')\n","\n","tf_accuracy.update_state(y_true_tf, y_pred_tf)\n","tf_precision.update_state(y_true_tf, y_pred_tf)\n","tf_recall.update_state(y_true_tf, y_pred_tf)\n","tf_meaniou.update_state(y_true_tf, y_pred_tf)\n","tf_iou.update_state(y_true_tf, y_pred_tf)\n","tf_f1.update_state(y_true_tf, y_pred_tf )\n","\n","\n","\n","def custom_erosion_tf(mask, kernel_size=3):\n","    kernel = tf.ones((kernel_size, kernel_size, 1, 1), dtype=tf.float32)\n","    mask = tf.expand_dims(tf.expand_dims(mask, axis=0), axis=-1)  # Add batch and channel dimensions\n","    eroded = tf.nn.convolution(mask, filters=kernel, padding='SAME')\n","    eroded = tf.cast(eroded == tf.reduce_max(kernel), tf.float32)\n","    return tf.squeeze(eroded)  # Remove batch and channel dimensions\n","\n","def custom_dilation_tf(mask, kernel_size=3):\n","    kernel = tf.ones((kernel_size, kernel_size, 1, 1), dtype=tf.float32)\n","    mask = tf.expand_dims(tf.expand_dims(mask, axis=0), axis=-1)  # Add batch and channel dimensions\n","    dilated = tf.nn.convolution(mask, filters=kernel, padding='SAME')\n","    dilated = tf.cast(dilated \u003e 0, tf.float32)\n","    return tf.squeeze(dilated)  # Remove batch and channel dimensions\n","\n","def extract_boundaries_tf(mask):\n","    \"\"\"Extract boundary pixels from a binary segmentation mask using TensorFlow.\"\"\"\n","    mask = tf.convert_to_tensor(mask, dtype=tf.float32)\n","    eroded_mask = custom_erosion_tf(mask, kernel_size=3)\n","    boundary = tf.cast(mask, tf.bool) ^ tf.cast(eroded_mask, tf.bool)\n","    return tf.cast(boundary, tf.float32)\n","\n","def boundary_f1_score_tf(y_true, y_pred, dilation_radius=1):\n","    \"\"\"Compute the Boundary F1 Score between the predicted and ground truth masks using TensorFlow.\"\"\"\n","    y_true_boundary = extract_boundaries_tf(y_true)\n","    y_pred_boundary = extract_boundaries_tf(y_pred)\n","\n","    # Dilate the boundaries to allow for some tolerance\n","    y_true_boundary_dilated = custom_dilation_tf(y_true_boundary, kernel_size=2*dilation_radius+1)\n","    y_pred_boundary_dilated = custom_dilation_tf(y_pred_boundary, kernel_size=2*dilation_radius+1)\n","\n","    # Flatten the boundaries\n","    y_true_boundary_flat = tf.reshape(y_true_boundary_dilated, [-1])\n","    y_pred_boundary_flat = tf.reshape(y_pred_boundary_dilated, [-1])\n","\n","    # Calculate Precision and Recall\n","    precision = Precision()\n","    recall = Recall()\n","    precision.update_state(y_true_boundary_flat, y_pred_boundary_flat)\n","    recall.update_state(y_true_boundary_flat, y_pred_boundary_flat)\n","\n","    precision_value = precision.result().numpy()\n","    recall_value = recall.result().numpy()\n","\n","    # Compute F1 score\n","    f1_value = 2 * (precision_value * recall_value) / (precision_value + recall_value + tf.keras.backend.epsilon())\n","    return f1_value\n","bf_score_tf = boundary_f1_score_tf(y_true, y_pred)\n","\n","\n","def pairwise_distances_tf(a, b):\n","    \"\"\"Compute pairwise distances between each point in array a and array b.\"\"\"\n","    a = tf.expand_dims(a, axis=1)\n","    b = tf.expand_dims(b, axis=0)\n","    return tf.reduce_sum(tf.square(a - b), axis=-1)\n","\n","def hausdorff_distance_tf(y_true, y_pred):\n","    \"\"\"Calculate Hausdorff Distance using TensorFlow.\"\"\"\n","    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n","    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n","\n","    y_true_points = tf.where(tf.equal(y_true, 1))\n","    y_pred_points = tf.where(tf.equal(y_pred, 1))\n","\n","    if tf.size(y_true_points) == 0 or tf.size(y_pred_points) == 0:\n","        return tf.constant(np.inf)\n","\n","    distances = pairwise_distances_tf(y_true_points, y_pred_points)\n","    forward_hausdorff = tf.reduce_max(tf.reduce_min(distances, axis=1))\n","    backward_hausdorff = tf.reduce_max(tf.reduce_min(distances, axis=0))\n","    hd = tf.maximum(forward_hausdorff, backward_hausdorff)\n","    return hd.numpy()\n","\n","hd_tf = hausdorff_distance_tf(y_true, y_pred)\n","\n","\n","\n","results['TensorFlow'] = {\n","    'Accuracy': tf_accuracy.result().numpy(),\n","    'Precision': tf_precision.result().numpy(),\n","    'Recall': tf_recall.result().numpy(),\n","    'MeanIoU': tf_meaniou.result().numpy(),\n","    'IoU': tf_iou.result().numpy(),\n","    'F1 Score': tf_f1.result().numpy(),\n","    'BF Score': bf_score_tf,\n","    'Hausdorff Distance': hd_tf\n","}"]},{"cell_type":"markdown","metadata":{"id":"iGnmQmS3F6n8"},"source":["#**PyTorch Library:**"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":6810,"status":"ok","timestamp":1729952391636,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"V-D9xjtlF3uG"},"outputs":[],"source":["y_true_torch = torch.tensor(y_true, dtype=torch.int)\n","y_pred_torch = torch.tensor(y_pred, dtype=torch.int)\n","\n","accuracy_metric = torchmetrics.Accuracy(task=\"binary\")\n","precision_metric = torchmetrics.Precision(task=\"binary\")\n","recall_metric = torchmetrics.Recall(task=\"binary\")\n","f1_metric = torchmetrics.F1Score(task=\"binary\")\n","iou_metric = torchmetrics.JaccardIndex(task=\"binary\")\n","\n","\n","accuracy_metric.update(y_pred_torch, y_true_torch)\n","precision_metric.update(y_pred_torch, y_true_torch)\n","recall_metric.update(y_pred_torch, y_true_torch)\n","f1_metric.update(y_pred_torch, y_true_torch)\n","iou_metric.update(y_pred_torch, y_true_torch)\n","\n","pt_accuracy = accuracy_metric.compute().item()\n","pt_precision = precision_metric.compute().item()\n","pt_recall = recall_metric.compute().item()\n","pt_f1 = f1_metric.compute().item()\n","pt_iou = iou_metric.compute().item()\n","\n","\n","def extract_boundaries_torch(mask):\n","    \"\"\"Extract boundary pixels from a binary segmentation mask using PyTorch.\"\"\"\n","    mask = torch.tensor(mask, dtype=torch.float32)\n","    eroded_mask = F.max_pool2d(mask.unsqueeze(0).unsqueeze(0), kernel_size=3, stride=1, padding=1).squeeze()\n","    boundary = (mask != eroded_mask).float()\n","    return boundary\n","\n","def custom_dilation_torch(mask, kernel_size=3):\n","    \"\"\"Dilate the boundary pixels.\"\"\"\n","    kernel = torch.ones((1, 1, kernel_size, kernel_size), dtype=torch.float32)\n","    mask = mask.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n","    dilated = F.conv2d(mask, kernel, padding=kernel_size // 2).squeeze()\n","    dilated = (dilated \u003e 0).float()\n","    return dilated\n","\n","def boundary_f1_score_torch(y_true, y_pred, dilation_radius=1):\n","    \"\"\"Compute the Boundary F1 Score between the predicted and ground truth masks using PyTorch.\"\"\"\n","    y_true_boundary = extract_boundaries_torch(y_true)\n","    y_pred_boundary = extract_boundaries_torch(y_pred)\n","\n","    # Dilate the boundaries to allow for some tolerance\n","    y_true_boundary_dilated = custom_dilation_torch(y_true_boundary, kernel_size=2*dilation_radius+1)\n","    y_pred_boundary_dilated = custom_dilation_torch(y_pred_boundary, kernel_size=2*dilation_radius+1)\n","\n","    # Flatten the boundaries\n","    y_true_boundary_flat = y_true_boundary_dilated.flatten()\n","    y_pred_boundary_flat = y_pred_boundary_dilated.flatten()\n","\n","    # Calculate Precision and Recall\n","    precision_metric = Precision('binary')\n","    recall_metric = Recall('binary')\n","\n","    precision_metric.update(y_pred_boundary_flat, y_true_boundary_flat)\n","    recall_metric.update(y_pred_boundary_flat, y_true_boundary_flat)\n","\n","    precision_value = precision_metric.compute().item()\n","    recall_value = recall_metric.compute().item()\n","\n","    # Compute F1 score\n","    f1_value = 2 * (precision_value * recall_value) / (precision_value + recall_value + 1e-6)\n","    return f1_value\n","\n","bf_score_torch = boundary_f1_score_torch(y_true, y_pred)\n","\n","\n","\n","def hausdorff_distance_torch(y_true, y_pred):\n","    \"\"\"Calculate Hausdorff Distance using PyTorch.\"\"\"\n","    y_true = torch.tensor(y_true, dtype=torch.float32)\n","    y_pred = torch.tensor(y_pred, dtype=torch.float32)\n","    y_true_points = torch.nonzero(y_true, as_tuple=False).float()\n","    y_pred_points = torch.nonzero(y_pred, as_tuple=False).float()\n","\n","    if y_true_points.size(0) == 0 or y_pred_points.size(0) == 0:\n","        return float('inf')\n","\n","    dists = torch.cdist(y_true_points.unsqueeze(0), y_pred_points.unsqueeze(0)).squeeze(0)\n","    forward_hausdorff = torch.max(torch.min(dists, dim=1)[0])\n","    backward_hausdorff = torch.max(torch.min(dists, dim=0)[0])\n","    hd = torch.max(forward_hausdorff, backward_hausdorff)\n","    return hd.item()\n","hd_torch = hausdorff_distance_torch(y_true, y_pred)\n","\n","results['PyTorch/torchmetrics'] = {\n","    'Accuracy': pt_accuracy,\n","    'Precision': pt_precision,\n","    'Recall': pt_recall,\n","    'F1 Score': pt_f1,\n","    'IoU': pt_iou,\n","    'Dice Coefficient': dice(y_pred_torch, y_true_torch).item(),\n","    'BF Score': bf_score_torch,\n","    'Hausdorff Distance': hd_torch\n","}"]},{"cell_type":"markdown","metadata":{"id":"DledNfzlHCj1"},"source":["#**Scikit Learn Library:**"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1729952026252,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"syv8o10pHB40"},"outputs":[],"source":["def extract_boundaries_skl(mask):\n","    \"\"\" Extract boundary pixels from a binary segmentation mask. \"\"\"\n","    structuring_element = disk(1)\n","    eroded_mask = binary_erosion(mask, structuring_element)\n","    boundary = mask ^ eroded_mask\n","    return boundary\n","\n","def boundary_f1_score_skl(y_true, y_pred, dilation_radius=1):\n","    \"\"\" Compute the Boundary F1 Score between the predicted and ground truth masks. \"\"\"\n","    y_true_boundary = extract_boundaries_skl(y_true)\n","    y_pred_boundary = extract_boundaries_skl(y_pred)\n","\n","    # Dilate the boundaries to allow for some tolerance\n","    structuring_element = disk(dilation_radius)\n","    y_true_boundary_dilated = binary_dilation(y_true_boundary, structuring_element)\n","    y_pred_boundary_dilated = binary_dilation(y_pred_boundary, structuring_element)\n","\n","    # Flatten the boundaries\n","    y_true_boundary_flat = y_true_boundary_dilated.flatten()\n","    y_pred_boundary_flat = y_pred_boundary_dilated.flatten()\n","\n","    # Compute F1 score\n","    bf_score = f1_score(y_true_boundary_flat, y_pred_boundary_flat)\n","    return bf_score\n","\n","bf_score_skl = boundary_f1_score_skl(y_true, y_pred)\n","\n","sklearn_accuracy = accuracy_score(y_true_flat, y_pred_flat)\n","sklearn_precision = precision_score(y_true_flat, y_pred_flat)\n","sklearn_recall = recall_score(y_true_flat, y_pred_flat)\n","sklearn_f1 = f1_score(y_true_flat, y_pred_flat)\n","sklearn_jaccard = jaccard_score(y_true_flat, y_pred_flat)\n","sklearn_kappa = cohen_kappa_score(y_true_flat, y_pred_flat)\n","\n","results['Scikit-Learn'] = {\n","    'Accuracy': sklearn_accuracy,\n","    'Precision': sklearn_precision,\n","    'Recall': sklearn_recall,\n","    'F1 Score': sklearn_f1,\n","    'IoU': sklearn_jaccard,\n","    'Kappa': sklearn_kappa,\n","    'BF Score': bf_score_skl\n","}"]},{"cell_type":"markdown","metadata":{"id":"4aT7hs4fHX7m"},"source":["#**Sicikit Image Library:**"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2873,"status":"ok","timestamp":1729952029123,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"rPMciLmaHgqw"},"outputs":[],"source":["def extract_boundaries_ski(mask):\n","    \"\"\" Extract boundary pixels from a binary segmentation mask. \"\"\"\n","    structuring_element = disk(1)\n","    eroded_mask = binary_erosion(mask, structure=structuring_element)\n","    boundary = mask ^ eroded_mask\n","    return boundary\n","\n","def boundary_f1_score_ski(pred, gt, dilation_radius=1):\n","    \"\"\" Compute the Boundary F1 Score between the predicted and ground truth masks. \"\"\"\n","    pred_boundary = extract_boundaries_ski(pred)\n","    gt_boundary = extract_boundaries_ski(gt)\n","\n","    # Dilate the boundaries to allow for tolerance in matching\n","    structuring_element = disk(dilation_radius)\n","    pred_boundary_dilated = binary_dilation(pred_boundary, structuring_element)\n","    gt_boundary_dilated = binary_dilation(gt_boundary, structuring_element)\n","\n","    # True positives\n","    true_positives = np.sum(pred_boundary \u0026 gt_boundary_dilated)\n","    # False positives\n","    false_positives = np.sum(pred_boundary \u0026 ~gt_boundary_dilated)\n","    # False negatives\n","    false_negatives = np.sum(gt_boundary \u0026 ~pred_boundary_dilated)\n","\n","    if true_positives + false_positives == 0 or true_positives + false_negatives == 0:\n","        return 0.0\n","\n","    # Precision and recall\n","    precision = true_positives / (true_positives + false_positives)\n","    recall = true_positives / (true_positives + false_negatives)\n","\n","    # F1 Score\n","    bf_score = 2 * (precision * recall) / (precision + recall)\n","    return bf_score\n","\n","bf_score_ski = boundary_f1_score_ski(y_pred, y_true)\n","hd_ski = hausdorff_distance(y_true, y_pred)\n","\n","results['Scikit-Image'] = {\n","    'BF Score': bf_score_ski,\n","    'Hausdorff Distance': hd_ski\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"gUXyqEOHHqFY"},"source":["#**SimpleITK Library:**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"EDyb07eTH-uA"},"outputs":[],"source":["def extract_boundaries_itk(mask):\n","    \"\"\" Extract boundary pixels from a binary segmentation mask using SimpleITK. \"\"\"\n","    mask_sitk = sitk.GetImageFromArray(mask.astype(np.uint8))\n","    eroded_mask_sitk = sitk.BinaryErode(mask_sitk, (1,1))\n","    eroded_mask = sitk.GetArrayFromImage(eroded_mask_sitk)\n","    boundary = mask ^ eroded_mask\n","    return boundary\n","\n","def boundary_f1_score_itk(pred, gt, dilation_radius=1):\n","    \"\"\" Compute the Boundary F1 Score between the predicted and ground truth masks using SimpleITK. \"\"\"\n","    pred_boundary = extract_boundaries_itk(pred)\n","    gt_boundary = extract_boundaries_itk(gt)\n","\n","    # Dilate the boundaries to allow for tolerance in matching\n","    pred_boundary_sitk = sitk.GetImageFromArray(pred_boundary.astype(np.uint8))\n","    gt_boundary_sitk = sitk.GetImageFromArray(gt_boundary.astype(np.uint8))\n","\n","    pred_boundary_dilated = sitk.BinaryDilate(pred_boundary_sitk, (dilation_radius, dilation_radius))\n","    gt_boundary_dilated = sitk.BinaryDilate(gt_boundary_sitk, (dilation_radius, dilation_radius))\n","\n","    pred_boundary_dilated = sitk.GetArrayFromImage(pred_boundary_dilated)\n","    gt_boundary_dilated = sitk.GetArrayFromImage(gt_boundary_dilated)\n","\n","    # True positives\n","    true_positives = np.sum(pred_boundary \u0026 gt_boundary_dilated)\n","    # False positives\n","    false_positives = np.sum(pred_boundary \u0026 ~gt_boundary_dilated)\n","    # False negatives\n","    false_negatives = np.sum(gt_boundary \u0026 ~pred_boundary_dilated)\n","\n","    if true_positives + false_positives == 0 or true_positives + false_negatives == 0:\n","        return 0.0\n","\n","    # Precision and recall\n","    precision = true_positives / (true_positives + false_positives)\n","    recall = true_positives / (true_positives + false_negatives)\n","\n","    # F1 Score\n","    bf_score = 2 * (precision * recall) / (precision + recall)\n","    return bf_score\n","bf_score_itk = boundary_f1_score_itk(y_pred, y_true)\n","\n","def calculate_iou_sitk(y_true, y_pred):\n","    \"\"\"Calculate Intersection over Union (IoU) using SimpleITK.\"\"\"\n","    # Convert numpy arrays to SimpleITK images\n","    y_true_sitk = sitk.GetImageFromArray(y_true)\n","    y_pred_sitk = sitk.GetImageFromArray(y_pred)\n","\n","    # Calculate the intersection and union\n","    intersection = sitk.And(y_true_sitk, y_pred_sitk)\n","    union = sitk.Or(y_true_sitk, y_pred_sitk)\n","\n","    # Convert back to numpy arrays\n","    intersection_array = sitk.GetArrayFromImage(intersection)\n","    union_array = sitk.GetArrayFromImage(union)\n","\n","    # Compute IoU\n","    iou = np.sum(intersection_array) / np.sum(union_array)\n","    return iou\n","\n","iou_value_sitk = calculate_iou_sitk(y_true, y_pred)\n","\n","\n","y_true_sitk = sitk.GetImageFromArray(y_true.astype(np.uint8))\n","y_pred_sitk = sitk.GetImageFromArray(y_pred.astype(np.uint8))\n","\n","hausdorff_filter = sitk.HausdorffDistanceImageFilter()\n","hausdorff_filter.Execute(y_true_sitk, y_pred_sitk)\n","hd_itk = hausdorff_filter.GetHausdorffDistance()\n","\n","import numpy as np\n","import SimpleITK as sitk\n","\n","def dice_coefficient_itk(y_true, y_pred):\n","    \"\"\"Calculate Dice Coefficient using SimpleITK.\"\"\"\n","    # Convert numpy arrays to SimpleITK images\n","    y_true_sitk = sitk.GetImageFromArray(y_true)\n","    y_pred_sitk = sitk.GetImageFromArray(y_pred)\n","\n","    # Calculate Dice Coefficient\n","    dice_filter = sitk.LabelOverlapMeasuresImageFilter()\n","    dice_filter.Execute(y_true_sitk, y_pred_sitk)\n","    dice_value = dice_filter.GetDiceCoefficient()\n","    return dice_value\n","\n","dice_itk = dice_coefficient_itk(y_true, y_pred)\n","\n","results['SimpleITK'] = {\n","    'BF Score': bf_score_itk,\n","    'IoU': iou_value_sitk,\n","    'Hausdorff Distance': hd_itk,\n","    'Dice Coefficient': dice_itk\n","}"]},{"cell_type":"markdown","metadata":{"id":"J-COLYAlIEET"},"source":["#**Medpy Library:**"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"AtXdXtrlINMi"},"outputs":[],"source":["def extract_boundaries_med(mask):\n","    \"\"\" Extract boundary pixels from a binary segmentation mask. \"\"\"\n","    structuring_element = disk(1)\n","    eroded_mask = binary_erosion(mask, structuring_element)\n","    boundary = mask ^ eroded_mask\n","    return boundary\n","\n","def compute_surface_distances_med(pred_boundary, gt_boundary):\n","    \"\"\" Compute the surface distances using MedPy. \"\"\"\n","    return __surface_distances(pred_boundary, gt_boundary)\n","\n","def boundary_f1_score_med(pred, gt, dilation_radius=1):\n","    \"\"\" Compute the Boundary F1 Score between the predicted and ground truth masks using MedPy. \"\"\"\n","    pred_boundary = extract_boundaries_med(pred)\n","    gt_boundary = extract_boundaries_med(gt)\n","\n","    # Dilate the boundaries to allow for tolerance in matching\n","    structuring_element = disk(dilation_radius)\n","    pred_boundary_dilated = binary_dilation(pred_boundary, structuring_element)\n","    gt_boundary_dilated = binary_dilation(gt_boundary, structuring_element)\n","\n","    # Compute surface distances using MedPy\n","    pred_to_gt_distances = compute_surface_distances_med(pred_boundary, gt_boundary_dilated)\n","    gt_to_pred_distances = compute_surface_distances_med(gt_boundary, pred_boundary_dilated)\n","\n","    # # True positives\n","    true_positives = np.sum(pred_boundary \u0026 gt_boundary_dilated)\n","    # False positives\n","    false_positives = np.sum(pred_boundary \u0026 ~gt_boundary_dilated)\n","    # False negatives\n","    false_negatives = np.sum(gt_boundary \u0026 ~pred_boundary_dilated)\n","    #false_negatives = np.sum(gt_boundary_dilated \u0026 ~pred_boundary)\n","\n","    if true_positives + false_positives == 0 or true_positives + false_negatives == 0:\n","        return 0.0\n","\n","    # Precision and recall\n","    precision = true_positives / (true_positives + false_positives)\n","    recall = true_positives / (true_positives + false_negatives)\n","\n","    # F1 Score\n","    bf_score = 2 * (precision * recall) / (precision + recall)\n","    return bf_score\n","\n","bf_score_med = boundary_f1_score_med(y_pred, y_true)\n","dc_medpy = dc(y_true, y_pred)\n","hausdorff_distance_med = hd(y_true, y_pred)\n","\n","# Compute Jaccard Index (IoU)\n","iou_medpy = jc(y_true, y_pred)\n","\n","precision_medpy = precision(y_pred, y_true)\n","recall_medpy = recall(y_pred, y_true)\n","\n","f1_medpy = 2 * (precision_medpy * recall_medpy) / (precision_medpy + recall_medpy)\n","\n","results['Medpy'] = {\n","    'BF Score': bf_score_med,\n","    'Dice Coefficient': dc_medpy,\n","    'Hausdorff Distance' : hausdorff_distance_med,\n","    'IoU': iou_medpy,\n","    'Precision': precision_medpy,\n","    'Recall': recall_medpy,\n","    'F1 Score': f1_medpy\n","}"]},{"cell_type":"markdown","metadata":{"id":"PcnMc6d_IRhc"},"source":["#**Imbalanced Learn Library:**"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"8z7RizrMIZPq"},"outputs":[],"source":["results['Imbalanced-learn'] = {\n","    'Geometric Mean': geometric_mean_score(y_true_flat, y_pred_flat)\n","}"]},{"cell_type":"markdown","metadata":{"id":"-r-oDmQuI1Ux"},"source":["#**Numpy Library:**"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"Yh_q5B49I5jq"},"outputs":[],"source":["def calculate_iou(y_true, y_pred):\n","    intersection = np.logical_and(y_true, y_pred)\n","    union = np.logical_or(y_true, y_pred)\n","    return np.sum(intersection) / np.sum(union)\n","\n","# Function to calculate Dice coefficient\n","def calculate_dice(y_true, y_pred):\n","    intersection = np.logical_and(y_true, y_pred)\n","    return 2 * np.sum(intersection) / (np.sum(y_true) + np.sum(y_pred))\n","\n","# Function to calculate Pixel Accuracy\n","def calculate_pixel_accuracy(y_true, y_pred):\n","    return np.sum(y_true == y_pred) / y_true.size\n","\n","y_true_points = np.column_stack(np.where(y_true == 1))\n","y_pred_points = np.column_stack(np.where(y_pred == 1))\n","hd_scipy = max(directed_hausdorff(y_true_points, y_pred_points)[0],\n","                directed_hausdorff(y_pred_points, y_true_points)[0])\n","\n","results['Numpy'] = {\n","    'IoU': calculate_iou(y_true, y_pred),\n","    'Dice Coefficient': calculate_dice(y_true, y_pred),\n","    'Accuracy': calculate_pixel_accuracy(y_true, y_pred),\n","    'Hausdorff Distance': hd_scipy\n","}"]},{"cell_type":"markdown","metadata":{"id":"Vv6bhl-MI92H"},"source":["#**hausdorff Library:**"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"4UPjko5XJGpB"},"outputs":[],"source":["distance_haus = hausdorff_distance(y_pred, y_true)\n","\n","results['hausdorff'] = {\n","    'Hausdorff Distance': distance_haus\n","}"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1729952029124,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"w7iwFzAYG-RQ","outputId":"c649532e-3db0-4662-eff3-3987a207f345"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                    Accuracy                   Precision  \\\n","TensorFlow       0.4956054687500000000000000 0.4922054409980773925781250   \n","Scikit-Learn     0.4956054687500000000000000 0.4922054380664652728505359   \n","Scikit-Image                             NaN                         NaN   \n","SimpleITK                                NaN                         NaN   \n","Medpy                                    NaN 0.4922054380664652728505359   \n","Imbalanced-learn                         NaN                         NaN   \n","Numpy            0.4956054687500000000000000                         NaN   \n","hausdorff                                NaN                         NaN   \n","\n","                                      Recall                     MeanIoU  \\\n","TensorFlow       0.5006760954856872558593750 0.3294377326965332031250000   \n","Scikit-Learn     0.5006760909649662361076139                         NaN   \n","Scikit-Image                             NaN                         NaN   \n","SimpleITK                                NaN                         NaN   \n","Medpy            0.5006760909649662361076139                         NaN   \n","Imbalanced-learn                         NaN                         NaN   \n","Numpy                                    NaN                         NaN   \n","hausdorff                                NaN                         NaN   \n","\n","                                         IoU                    F1 Score  \\\n","TensorFlow       0.3301450610160827636718750 0.4964045584201812744140625   \n","Scikit-Learn     0.3301450919996757882302063 0.4964046313223643980272470   \n","Scikit-Image                             NaN                         NaN   \n","SimpleITK        0.3301450919996757882302063                         NaN   \n","Medpy            0.3301450919996757882302063 0.4964046313223644535383983   \n","Imbalanced-learn                         NaN                         NaN   \n","Numpy            0.3301450919996757882302063                         NaN   \n","hausdorff                                NaN                         NaN   \n","\n","                                    BF Score          Hausdorff Distance  \\\n","TensorFlow       0.9983492761270830184727743 5.0000000000000000000000000   \n","Scikit-Learn     0.9666235119517508911357595                         NaN   \n","Scikit-Image     0.9664612390528706242776025 7.3484692283495345321853165   \n","SimpleITK        0.9972652689152233795866209 2.2360679774997898050514777   \n","Medpy            0.9664612390528706242776025 2.2360679774997898050514777   \n","Imbalanced-learn                         NaN                         NaN   \n","Numpy                                    NaN 2.2360679774997898050514777   \n","hausdorff                                NaN 7.3484692283495345321853165   \n","\n","                                        Kappa            Dice Coefficient  \\\n","TensorFlow                                NaN                         NaN   \n","Scikit-Learn     -0.0087179505136030233103384                         NaN   \n","Scikit-Image                              NaN                         NaN   \n","SimpleITK                                 NaN 0.4964046313223644535383983   \n","Medpy                                     NaN 0.4964046313223643980272470   \n","Imbalanced-learn                          NaN                         NaN   \n","Numpy                                     NaN 0.4964046313223643980272470   \n","hausdorff                                 NaN                         NaN   \n","\n","                              Geometric Mean  \n","TensorFlow                               NaN  \n","Scikit-Learn                             NaN  \n","Scikit-Image                             NaN  \n","SimpleITK                                NaN  \n","Medpy                                    NaN  \n","Imbalanced-learn 0.4956149255817008381086453  \n","Numpy                                    NaN  \n","hausdorff                                NaN  \n"]}],"source":["results_df = pd.DataFrame(results).T\n","#results_df.index.name = 'Library'  # Set index name for better readability\n","#results_df.reset_index(inplace=True)  # Reset index to make 'Library' a column\n","#results_df = results_df.rename_axis(None, axis=1)  # Remove axis name for columns\n","print(results_df)"]},{"cell_type":"markdown","metadata":{"id":"ju45Y0sx0DL5"},"source":["# Segmentation Model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1729952029125,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"0lsYvtP30C8e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1729952029125,"user":{"displayName":"Ghazal Mousavi","userId":"18391534113529090965"},"user_tz":-210},"id":"da8NRhopJYuT"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}